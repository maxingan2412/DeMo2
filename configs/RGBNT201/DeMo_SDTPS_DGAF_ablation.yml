MODEL:
  TRANSFORMER_TYPE: 'ViT-B-16'
  STRIDE_SIZE: [ 16, 16 ]
  SIE_CAMERA: True
  DIRECT: 1
  SIE_COE: 1.0
  ID_LOSS_WEIGHT: 0.25
  TRIPLET_LOSS_WEIGHT: 1.0
  GLOBAL_LOCAL: False  # DGAF V3 直接用 tokens，不需要 GLOBAL_LOCAL
  # Disable HDM and ATM
  HDM: False
  ATM: False
  # SACR disabled for ablation
  USE_SACR: False
  USE_MULTIMODAL_SACR: False
  # LIF disabled
  USE_LIF: False
  # SDTPS configuration
  USE_SDTPS: True
  SDTPS_SPARSE_RATIO: 0.7  # token 保留比例（70%）
  SDTPS_USE_GUMBEL: False  # 禁用 Gumbel（训练稳定性）
  SDTPS_GUMBEL_TAU: 5.0
  SDTPS_CROSS_ATTN_TYPE: 'attention'  # 使用 Cross-Attention（推荐）
  SDTPS_CROSS_ATTN_HEADS: 4  # Cross-Attention 头数
  # 已废弃参数（保留兼容性）
  SDTPS_BETA: 0.25         # 已不使用（原 MLP predictor 权重）
  SDTPS_AGGR_RATIO: 0.5    # 已不使用（原 TokenAggregation）
  SDTPS_LOSS_WEIGHT: 2.0   # SDTPS 分支的损失权重
  # DGAF: Dual-Gated Adaptive Fusion
  USE_DGAF: True
  DGAF_VERSION: 'v3'  # V3 接受 (B,N,C) tokens
  DGAF_TAU: 1.0
  DGAF_INIT_ALPHA: 0.5
  DGAF_NUM_HEADS: 8
  HEAD: 4

INPUT:
  SIZE_TRAIN: [ 256, 128 ]
  SIZE_TEST: [ 256, 128 ]
  PROB: 0.5
  RE_PROB: 0.5
  PADDING: 10

DATALOADER:
  SAMPLER: 'softmax_triplet'
  NUM_INSTANCE: 8
  NUM_WORKERS: 14

DATASETS:
  NAMES: ('RGBNT201')
  ROOT_DIR: '..'

SOLVER:
  BASE_LR: 0.000005
  LR_SCHEDULER: 'linear'
  MAX_EPOCHS: 50
  STEPS: [30, 40]
  GAMMA: 0.1
  WARMUP_ITERS: 0
  WARMUP_FACTOR: 0.01
  WARMUP_METHOD: 'linear'
  OPTIMIZER_NAME: 'Adam'
  IMS_PER_BATCH: 64
  EVAL_PERIOD: 1
  CHECKPOINT_PERIOD: 10

TEST:
  IMS_PER_BATCH: 128
  RE_RANKING: 'no'
  WEIGHT: ''
  NECK_FEAT: 'before'
  FEAT_NORM: 'yes'
  MISS: "nothing"

OUTPUT_DIR: '..'

# ============================================================================
# SDTPS + DGAF Ablation Config
# ============================================================================
# - SACR: disabled
# - SDTPS: configurable via command line
# - DGAF V3: configurable via command line
# - Training: lr=0.00035, epochs=50, warmup=10
# - TF32: enabled in train_net.py
# ============================================================================
