2025-12-09 13:20:45,076 DeMo INFO: Saving model in the path :..
2025-12-09 13:20:45,076 DeMo INFO: Namespace(config_file='configs/RGBNT201/DeMo_SDTPS_DGAF_ablation.yml', exp_name=None, fea_cft=0, local_rank=0, opts=['MODEL.USE_SDTPS', 'False', 'MODEL.USE_DGAF', 'True', 'MODEL.DGAF_VERSION', 'v3', 'MODEL.GLOBAL_LOCAL', 'False'])
2025-12-09 13:20:45,076 DeMo INFO: Loaded configuration file configs/RGBNT201/DeMo_SDTPS_DGAF_ablation.yml
2025-12-09 13:20:45,077 DeMo INFO: 
MODEL:
  TRANSFORMER_TYPE: 'ViT-B-16'
  STRIDE_SIZE: [ 16, 16 ]
  SIE_CAMERA: True
  DIRECT: 1
  SIE_COE: 1.0
  ID_LOSS_WEIGHT: 0.25
  TRIPLET_LOSS_WEIGHT: 1.0
  GLOBAL_LOCAL: False  # DGAF V3 直接用 tokens，不需要 GLOBAL_LOCAL
  # Disable HDM and ATM
  HDM: False
  ATM: False
  # SACR disabled for ablation
  USE_SACR: False
  USE_MULTIMODAL_SACR: False
  # LIF disabled
  USE_LIF: False
  # SDTPS configuration
  USE_SDTPS: True
  SDTPS_SPARSE_RATIO: 0.7  # token 保留比例（70%）
  SDTPS_USE_GUMBEL: False  # 禁用 Gumbel（训练稳定性）
  SDTPS_GUMBEL_TAU: 5.0
  SDTPS_CROSS_ATTN_TYPE: 'attention'  # 使用 Cross-Attention（推荐）
  SDTPS_CROSS_ATTN_HEADS: 4  # Cross-Attention 头数
  # 已废弃参数（保留兼容性）
  SDTPS_BETA: 0.25         # 已不使用（原 MLP predictor 权重）
  SDTPS_AGGR_RATIO: 0.5    # 已不使用（原 TokenAggregation）
  SDTPS_LOSS_WEIGHT: 2.0   # SDTPS 分支的损失权重
  # DGAF: Dual-Gated Adaptive Fusion
  USE_DGAF: True
  DGAF_VERSION: 'v3'  # V3 接受 (B,N,C) tokens
  DGAF_TAU: 1.0
  DGAF_INIT_ALPHA: 0.5
  DGAF_NUM_HEADS: 8
  HEAD: 4

INPUT:
  SIZE_TRAIN: [ 256, 128 ]
  SIZE_TEST: [ 256, 128 ]
  PROB: 0.5
  RE_PROB: 0.5
  PADDING: 10

DATALOADER:
  SAMPLER: 'softmax_triplet'
  NUM_INSTANCE: 8
  NUM_WORKERS: 14

DATASETS:
  NAMES: ('RGBNT201')
  ROOT_DIR: '..'

SOLVER:
  BASE_LR: 0.000005
  LR_SCHEDULER: 'linear'
  MAX_EPOCHS: 50
  STEPS: [30, 40]
  GAMMA: 0.1
  WARMUP_ITERS: 0
  WARMUP_FACTOR: 0.01
  WARMUP_METHOD: 'linear'
  OPTIMIZER_NAME: 'Adam'
  IMS_PER_BATCH: 64
  EVAL_PERIOD: 1
  CHECKPOINT_PERIOD: 10

TEST:
  IMS_PER_BATCH: 128
  RE_RANKING: 'no'
  WEIGHT: ''
  NECK_FEAT: 'before'
  FEAT_NORM: 'yes'
  MISS: "nothing"

OUTPUT_DIR: '..'

# ============================================================================
# SDTPS + DGAF Ablation Config
# ============================================================================
# - SACR: disabled
# - SDTPS: configurable via command line
# - DGAF V3: configurable via command line
# - Training: lr=0.00035, epochs=50, warmup=10
# - TF32: enabled in train_net.py
# ============================================================================

2025-12-09 13:20:45,077 DeMo INFO: Running with config:
DATALOADER:
  NUM_INSTANCE: 8
  NUM_WORKERS: 14
  SAMPLER: softmax_triplet
DATASETS:
  NAMES: RGBNT201
  ROOT_DIR: ..
INPUT:
  PADDING: 10
  PIXEL_MEAN: [0.5, 0.5, 0.5]
  PIXEL_STD: [0.5, 0.5, 0.5]
  PROB: 0.5
  RE_PROB: 0.5
  SIZE_TEST: [256, 128]
  SIZE_TRAIN: [256, 128]
MODEL:
  ADAPTER: False
  ATM: False
  ATT_DROP_RATE: 0.0
  DEVICE: cuda
  DEVICE_ID: 0
  DGAF_INIT_ALPHA: 0.5
  DGAF_NUM_HEADS: 8
  DGAF_TAU: 1.0
  DGAF_VERSION: v3
  DIRECT: 1
  DIST_TRAIN: False
  DROP_OUT: 0.0
  DROP_PATH: 0.1
  FROZEN: False
  GLOBAL_LOCAL: False
  HDM: False
  HEAD: 4
  ID_LOSS_TYPE: softmax
  ID_LOSS_WEIGHT: 0.25
  IF_LABELSMOOTH: on
  IF_WITH_CENTER: no
  LIF_BETA: 0.4
  LIF_LAYER: 3
  LIF_LOSS_WEIGHT: 0.1
  METRIC_LOSS_TYPE: triplet
  MULTIMODAL_SACR_VERSION: v1
  NAME: DeMo
  NECK: bnneck
  NO_MARGIN: True
  PRETRAIN_PATH_T: /path/to/your/vitb_16_224_21k.pth
  PROMPT: False
  SACR_DILATION_RATES: [2, 3, 4]
  SDTPS_AGGR_RATIO: 0.5
  SDTPS_BETA: 0.25
  SDTPS_CROSS_ATTN_HEADS: 4
  SDTPS_CROSS_ATTN_TYPE: attention
  SDTPS_GUMBEL_TAU: 5.0
  SDTPS_LOSS_WEIGHT: 2.0
  SDTPS_SPARSE_RATIO: 0.7
  SDTPS_USE_GUMBEL: False
  SIE_CAMERA: True
  SIE_COE: 1.0
  SIE_VIEW: False
  STRIDE_SIZE: [16, 16]
  TRANSFORMER_TYPE: ViT-B-16
  TRIPLET_LOSS_WEIGHT: 1.0
  USE_DGAF: True
  USE_LIF: False
  USE_MULTIMODAL_SACR: False
  USE_SACR: False
  USE_SDTPS: False
OUTPUT_DIR: ..
SOLVER:
  BASE_LR: 5e-06
  CENTER_LOSS_WEIGHT: 0.0005
  CENTER_LR: 0.5
  CHECKPOINT_PERIOD: 10
  CLUSTER_MARGIN: 0.3
  COSINE_MARGIN: 0.5
  COSINE_SCALE: 30
  EVAL_PERIOD: 1
  GAMMA: 0.1
  IMS_PER_BATCH: 64
  LARGE_FC_LR: False
  LOG_PERIOD: 10
  LR_SCHEDULER: linear
  MARGIN: 0.3
  MAX_EPOCHS: 50
  MOMENTUM: 0.9
  OPTIMIZER_NAME: Adam
  RANGE_ALPHA: 0
  RANGE_BETA: 1
  RANGE_K: 2
  RANGE_LOSS_WEIGHT: 1
  RANGE_MARGIN: 0.3
  SEED: 1234
  STEPS: (30, 40)
  WARMUP_FACTOR: 0.01
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TEST:
  FEAT: 0
  FEAT_NORM: yes
  IMS_PER_BATCH: 128
  MISS: nothing
  NECK_FEAT: before
  RE_RANKING: no
  WEIGHT: 
=> RGBNT201 loaded
Dataset statistics:
  ----------------------------------------
  subset   | # ids | # images | # cameras
  ----------------------------------------
  train    |   171 |     3951 |         4
  query    |    30 |      836 |         2
  gallery  |    30 |      836 |         2
  ----------------------------------------
data is ready
using Transformer_type: ViT-B-16 as a backbone
Resized position embedding: %s to %s torch.Size([197, 768]) torch.Size([129, 768])
Position embedding resize to height:16 width: 8
Successfully load ckpt!
<All keys matched successfully>
Loading pretrained model from CLIP
camera number is : 4
===========Building DeMo===========
2025-12-09 13:20:54,952 DeMo INFO: DeMo(
  (BACKBONE): build_transformer(
    (base): VisionTransformer(
      (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
  )
  (pool): AdaptiveAvgPool1d(output_size=1)
  (rgb_reduce): Sequential(
    (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (1): Linear(in_features=1024, out_features=512, bias=True)
    (2): QuickGELU()
  )
  (nir_reduce): Sequential(
    (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (1): Linear(in_features=1024, out_features=512, bias=True)
    (2): QuickGELU()
  )
  (tir_reduce): Sequential(
    (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (1): Linear(in_features=1024, out_features=512, bias=True)
    (2): QuickGELU()
  )
  (dgaf): DualGatedAdaptiveFusionV3(
    (attn_pool): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
    )
    (attn_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (entropy_proj): Linear(in_features=512, out_features=512, bias=True)
    (gate_net): Sequential(
      (0): Linear(in_features=1536, out_features=512, bias=True)
      (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (2): ReLU(inplace=True)
      (3): Linear(in_features=512, out_features=3, bias=True)
      (4): Sigmoid()
    )
    (modal_enhance): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=True)
      (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
  )
  (classifier_dgaf): Linear(in_features=1536, out_features=171, bias=False)
  (bottleneck_dgaf): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (classifier): Linear(in_features=1536, out_features=171, bias=False)
  (bottleneck): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
)
2025-12-09 13:20:54,953 DeMo INFO: number of parameters:90.621444
/home/yij/miniconda3/envs/DeMo/lib/python3.8/site-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.models", FutureWarning)
/home/yij/miniconda3/envs/DeMo/lib/python3.8/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.models", FutureWarning)
/home/yij/miniconda3/envs/DeMo/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/raid/yij/icme/demo2new/DeMo2/modeling/clip/clip.py:23: UserWarning: PyTorch version 1.7.1 or higher is recommended
  warnings.warn("PyTorch version 1.7.1 or higher is recommended")
/home/yij/miniconda3/envs/DeMo/lib/python3.8/site-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
Unsupported operator aten::log encountered 3 time(s)
The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
BACKBONE.base.transformer.resblocks.0.attn.out_proj, BACKBONE.base.transformer.resblocks.1.attn.out_proj, BACKBONE.base.transformer.resblocks.10.attn.out_proj, BACKBONE.base.transformer.resblocks.11.attn.out_proj, BACKBONE.base.transformer.resblocks.2.attn.out_proj, BACKBONE.base.transformer.resblocks.3.attn.out_proj, BACKBONE.base.transformer.resblocks.4.attn.out_proj, BACKBONE.base.transformer.resblocks.5.attn.out_proj, BACKBONE.base.transformer.resblocks.6.attn.out_proj, BACKBONE.base.transformer.resblocks.7.attn.out_proj, BACKBONE.base.transformer.resblocks.8.attn.out_proj, BACKBONE.base.transformer.resblocks.9.attn.out_proj, bottleneck, bottleneck_dgaf, classifier, classifier_dgaf, dgaf.attn_pool.out_proj, nir_reduce, nir_reduce.0, nir_reduce.1, nir_reduce.2, pool, rgb_reduce, rgb_reduce.0, rgb_reduce.1, rgb_reduce.2, tir_reduce, tir_reduce.0, tir_reduce.1, tir_reduce.2
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The out_proj here is called by the nn.MultiheadAttention, which has been calculated in th .forward(), so just ignore it.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
For the bottleneck or classifier, it is not calculated during inference, so just ignore it.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:20:59,137 DeMo INFO: number of GFLOPs: 34.48054893099999
using soft triplet loss for training
label smooth on, numclasses: 171
2025-12-09 13:20:59,148 DeMo.train INFO: start training
/home/yij/miniconda3/envs/DeMo/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/home/yij/miniconda3/envs/DeMo/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:163: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.
  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)
2025-12-09 13:21:04,665 DeMo.train INFO: Epoch[1] Iteration[10/54] Loss: 8.472, Acc: 0.008, Base Lr: 5.00e-06
2025-12-09 13:21:07,162 DeMo.train INFO: Epoch[1] Iteration[20/54] Loss: 6.714, Acc: 0.008, Base Lr: 5.00e-06
2025-12-09 13:21:09,646 DeMo.train INFO: Epoch[1] Iteration[30/54] Loss: 5.954, Acc: 0.007, Base Lr: 5.00e-06
2025-12-09 13:21:12,118 DeMo.train INFO: Epoch[1] Iteration[40/54] Loss: 5.504, Acc: 0.006, Base Lr: 5.00e-06
2025-12-09 13:21:14,610 DeMo.train INFO: Epoch[1] Iteration[50/54] Loss: 5.215, Acc: 0.007, Base Lr: 5.00e-06
2025-12-09 13:21:15,485 DeMo.train INFO: Epoch 1 done. Time per batch: 0.308[s] Speed: 207.8[samples/s]
2025-12-09 13:21:15,486 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:21:15,486 DeMo.train INFO: Current is the [moe,ori] feature testing!
2025-12-09 13:21:15,486 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The test feature is normalized
=> Computing DistMat with euclidean_distance
2025-12-09 13:21:22,088 DeMo.train INFO: Validation Results - Epoch: 1
2025-12-09 13:21:22,089 DeMo.train INFO: mAP: 21.6%
2025-12-09 13:21:22,089 DeMo.train INFO: CMC curve, Rank-1  :19.6%
2025-12-09 13:21:22,091 DeMo.train INFO: CMC curve, Rank-5  :37.1%
2025-12-09 13:21:22,091 DeMo.train INFO: CMC curve, Rank-10 :46.1%
2025-12-09 13:21:22,093 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:22:08,205 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:22:08,207 DeMo.train INFO: Best mAP: 21.6%
2025-12-09 13:22:08,207 DeMo.train INFO: Best Rank-1: 19.6%
2025-12-09 13:22:08,208 DeMo.train INFO: Best Rank-5: 37.1%
2025-12-09 13:22:08,209 DeMo.train INFO: Best Rank-10: 46.1%
2025-12-09 13:22:08,209 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:22:18,219 DeMo.train INFO: Epoch[2] Iteration[10/54] Loss: 3.714, Acc: 0.023, Base Lr: 5.00e-06
2025-12-09 13:22:23,901 DeMo.train INFO: Epoch[2] Iteration[20/54] Loss: 3.695, Acc: 0.038, Base Lr: 5.00e-06
2025-12-09 13:22:29,584 DeMo.train INFO: Epoch[2] Iteration[30/54] Loss: 3.637, Acc: 0.041, Base Lr: 5.00e-06
2025-12-09 13:22:32,202 DeMo.train INFO: Epoch[2] Iteration[40/54] Loss: 3.608, Acc: 0.048, Base Lr: 5.00e-06
2025-12-09 13:22:34,750 DeMo.train INFO: Epoch[2] Iteration[50/54] Loss: 3.563, Acc: 0.056, Base Lr: 5.00e-06
2025-12-09 13:22:35,641 DeMo.train INFO: Epoch 2 done. Time per batch: 0.518[s] Speed: 123.7[samples/s]
2025-12-09 13:22:35,642 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:22:35,642 DeMo.train INFO: Current is the [moe,ori] feature testing!
2025-12-09 13:22:35,643 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The test feature is normalized
=> Computing DistMat with euclidean_distance
2025-12-09 13:22:40,539 DeMo.train INFO: Validation Results - Epoch: 2
2025-12-09 13:22:40,540 DeMo.train INFO: mAP: 46.3%
2025-12-09 13:22:40,541 DeMo.train INFO: CMC curve, Rank-1  :45.7%
2025-12-09 13:22:40,543 DeMo.train INFO: CMC curve, Rank-5  :59.4%
2025-12-09 13:22:40,543 DeMo.train INFO: CMC curve, Rank-10 :68.5%
2025-12-09 13:22:40,544 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:23:12,963 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:23:12,966 DeMo.train INFO: Best mAP: 46.3%
2025-12-09 13:23:12,966 DeMo.train INFO: Best Rank-1: 45.7%
2025-12-09 13:23:12,967 DeMo.train INFO: Best Rank-5: 59.4%
2025-12-09 13:23:12,967 DeMo.train INFO: Best Rank-10: 68.5%
2025-12-09 13:23:12,967 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:23:17,302 DeMo.train INFO: Epoch[3] Iteration[10/54] Loss: 3.174, Acc: 0.222, Base Lr: 5.00e-06
2025-12-09 13:23:19,816 DeMo.train INFO: Epoch[3] Iteration[20/54] Loss: 3.160, Acc: 0.211, Base Lr: 5.00e-06
2025-12-09 13:23:22,307 DeMo.train INFO: Epoch[3] Iteration[30/54] Loss: 3.108, Acc: 0.218, Base Lr: 5.00e-06
2025-12-09 13:23:24,805 DeMo.train INFO: Epoch[3] Iteration[40/54] Loss: 3.100, Acc: 0.230, Base Lr: 5.00e-06
2025-12-09 13:23:27,328 DeMo.train INFO: Epoch[3] Iteration[50/54] Loss: 3.063, Acc: 0.240, Base Lr: 5.00e-06
2025-12-09 13:23:28,229 DeMo.train INFO: Epoch 3 done. Time per batch: 0.288[s] Speed: 222.2[samples/s]
2025-12-09 13:23:28,233 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:23:28,234 DeMo.train INFO: Current is the [moe,ori] feature testing!
2025-12-09 13:23:28,234 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The test feature is normalized
=> Computing DistMat with euclidean_distance
2025-12-09 13:23:37,483 DeMo.train INFO: Validation Results - Epoch: 3
2025-12-09 13:23:37,484 DeMo.train INFO: mAP: 56.4%
2025-12-09 13:23:37,485 DeMo.train INFO: CMC curve, Rank-1  :58.9%
2025-12-09 13:23:37,486 DeMo.train INFO: CMC curve, Rank-5  :74.8%
2025-12-09 13:23:37,487 DeMo.train INFO: CMC curve, Rank-10 :78.9%
2025-12-09 13:23:37,488 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:24:26,529 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:24:26,530 DeMo.train INFO: Best mAP: 56.4%
2025-12-09 13:24:26,530 DeMo.train INFO: Best Rank-1: 58.9%
2025-12-09 13:24:26,531 DeMo.train INFO: Best Rank-5: 74.8%
2025-12-09 13:24:26,531 DeMo.train INFO: Best Rank-10: 78.9%
2025-12-09 13:24:26,531 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:24:31,449 DeMo.train INFO: Epoch[4] Iteration[10/54] Loss: 2.979, Acc: 0.409, Base Lr: 5.00e-06
2025-12-09 13:24:33,992 DeMo.train INFO: Epoch[4] Iteration[20/54] Loss: 2.875, Acc: 0.438, Base Lr: 5.00e-06
2025-12-09 13:24:36,524 DeMo.train INFO: Epoch[4] Iteration[30/54] Loss: 2.850, Acc: 0.406, Base Lr: 5.00e-06
2025-12-09 13:24:39,055 DeMo.train INFO: Epoch[4] Iteration[40/54] Loss: 2.831, Acc: 0.417, Base Lr: 5.00e-06
2025-12-09 13:24:41,649 DeMo.train INFO: Epoch[4] Iteration[50/54] Loss: 2.802, Acc: 0.419, Base Lr: 5.00e-06
2025-12-09 13:24:42,572 DeMo.train INFO: Epoch 4 done. Time per batch: 0.303[s] Speed: 211.5[samples/s]
2025-12-09 13:24:42,577 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:24:42,577 DeMo.train INFO: Current is the [moe,ori] feature testing!
2025-12-09 13:24:42,578 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The test feature is normalized
=> Computing DistMat with euclidean_distance
2025-12-09 13:24:47,565 DeMo.train INFO: Validation Results - Epoch: 4
2025-12-09 13:24:47,567 DeMo.train INFO: mAP: 59.4%
2025-12-09 13:24:47,568 DeMo.train INFO: CMC curve, Rank-1  :59.3%
2025-12-09 13:24:47,569 DeMo.train INFO: CMC curve, Rank-5  :72.2%
2025-12-09 13:24:47,570 DeMo.train INFO: CMC curve, Rank-10 :77.9%
2025-12-09 13:24:47,571 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:25:48,277 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:25:48,278 DeMo.train INFO: Best mAP: 59.4%
2025-12-09 13:25:48,279 DeMo.train INFO: Best Rank-1: 59.3%
2025-12-09 13:25:48,279 DeMo.train INFO: Best Rank-5: 72.2%
2025-12-09 13:25:48,280 DeMo.train INFO: Best Rank-10: 77.9%
2025-12-09 13:25:48,281 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:25:56,845 DeMo.train INFO: Epoch[5] Iteration[10/54] Loss: 2.813, Acc: 0.511, Base Lr: 5.00e-06
2025-12-09 13:26:00,062 DeMo.train INFO: Epoch[5] Iteration[20/54] Loss: 2.845, Acc: 0.524, Base Lr: 5.00e-06
2025-12-09 13:26:02,558 DeMo.train INFO: Epoch[5] Iteration[30/54] Loss: 2.809, Acc: 0.532, Base Lr: 5.00e-06
2025-12-09 13:26:05,051 DeMo.train INFO: Epoch[5] Iteration[40/54] Loss: 2.783, Acc: 0.544, Base Lr: 5.00e-06
2025-12-09 13:26:07,542 DeMo.train INFO: Epoch[5] Iteration[50/54] Loss: 2.752, Acc: 0.560, Base Lr: 5.00e-06
2025-12-09 13:26:08,451 DeMo.train INFO: Epoch 5 done. Time per batch: 0.381[s] Speed: 168.2[samples/s]
2025-12-09 13:26:08,455 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:26:08,456 DeMo.train INFO: Current is the [moe,ori] feature testing!
2025-12-09 13:26:08,457 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The test feature is normalized
=> Computing DistMat with euclidean_distance
2025-12-09 13:26:17,602 DeMo.train INFO: Validation Results - Epoch: 5
2025-12-09 13:26:17,603 DeMo.train INFO: mAP: 63.1%
2025-12-09 13:26:17,604 DeMo.train INFO: CMC curve, Rank-1  :65.1%
2025-12-09 13:26:17,605 DeMo.train INFO: CMC curve, Rank-5  :79.1%
2025-12-09 13:26:17,606 DeMo.train INFO: CMC curve, Rank-10 :84.2%
2025-12-09 13:26:17,607 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:26:38,418 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:26:38,419 DeMo.train INFO: Best mAP: 63.1%
2025-12-09 13:26:38,419 DeMo.train INFO: Best Rank-1: 65.1%
2025-12-09 13:26:38,419 DeMo.train INFO: Best Rank-5: 79.1%
2025-12-09 13:26:38,419 DeMo.train INFO: Best Rank-10: 84.2%
2025-12-09 13:26:38,419 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:26:42,538 DeMo.train INFO: Epoch[6] Iteration[10/54] Loss: 2.603, Acc: 0.658, Base Lr: 5.00e-06
2025-12-09 13:26:45,053 DeMo.train INFO: Epoch[6] Iteration[20/54] Loss: 2.624, Acc: 0.664, Base Lr: 5.00e-06
2025-12-09 13:26:47,555 DeMo.train INFO: Epoch[6] Iteration[30/54] Loss: 2.621, Acc: 0.680, Base Lr: 5.00e-06
2025-12-09 13:26:50,069 DeMo.train INFO: Epoch[6] Iteration[40/54] Loss: 2.623, Acc: 0.675, Base Lr: 5.00e-06
2025-12-09 13:26:52,587 DeMo.train INFO: Epoch[6] Iteration[50/54] Loss: 2.623, Acc: 0.693, Base Lr: 5.00e-06
2025-12-09 13:26:53,474 DeMo.train INFO: Epoch 6 done. Time per batch: 0.284[s] Speed: 225.3[samples/s]
2025-12-09 13:26:53,478 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:26:53,478 DeMo.train INFO: Current is the [moe,ori] feature testing!
2025-12-09 13:26:53,480 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The test feature is normalized
=> Computing DistMat with euclidean_distance
2025-12-09 13:27:02,676 DeMo.train INFO: Validation Results - Epoch: 6
2025-12-09 13:27:02,678 DeMo.train INFO: mAP: 66.6%
2025-12-09 13:27:02,678 DeMo.train INFO: CMC curve, Rank-1  :66.3%
2025-12-09 13:27:02,680 DeMo.train INFO: CMC curve, Rank-5  :79.2%
2025-12-09 13:27:02,681 DeMo.train INFO: CMC curve, Rank-10 :83.4%
2025-12-09 13:27:02,681 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:27:50,941 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:27:50,941 DeMo.train INFO: Best mAP: 66.6%
2025-12-09 13:27:50,942 DeMo.train INFO: Best Rank-1: 66.3%
2025-12-09 13:27:50,943 DeMo.train INFO: Best Rank-5: 79.2%
2025-12-09 13:27:50,943 DeMo.train INFO: Best Rank-10: 83.4%
2025-12-09 13:27:50,943 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:27:55,728 DeMo.train INFO: Epoch[7] Iteration[10/54] Loss: 2.575, Acc: 0.717, Base Lr: 5.00e-06
2025-12-09 13:27:58,228 DeMo.train INFO: Epoch[7] Iteration[20/54] Loss: 2.575, Acc: 0.702, Base Lr: 5.00e-06
2025-12-09 13:28:00,735 DeMo.train INFO: Epoch[7] Iteration[30/54] Loss: 2.614, Acc: 0.732, Base Lr: 5.00e-06
2025-12-09 13:28:03,239 DeMo.train INFO: Epoch[7] Iteration[40/54] Loss: 2.630, Acc: 0.745, Base Lr: 5.00e-06
2025-12-09 13:28:05,817 DeMo.train INFO: Epoch[7] Iteration[50/54] Loss: 2.622, Acc: 0.740, Base Lr: 5.00e-06
2025-12-09 13:28:06,692 DeMo.train INFO: Epoch 7 done. Time per batch: 0.297[s] Speed: 215.4[samples/s]
2025-12-09 13:28:06,695 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:28:06,695 DeMo.train INFO: Current is the [moe,ori] feature testing!
2025-12-09 13:28:06,695 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The test feature is normalized
=> Computing DistMat with euclidean_distance
2025-12-09 13:28:11,768 DeMo.train INFO: Validation Results - Epoch: 7
2025-12-09 13:28:11,769 DeMo.train INFO: mAP: 69.5%
2025-12-09 13:28:11,769 DeMo.train INFO: CMC curve, Rank-1  :70.6%
2025-12-09 13:28:11,770 DeMo.train INFO: CMC curve, Rank-5  :80.5%
2025-12-09 13:28:11,770 DeMo.train INFO: CMC curve, Rank-10 :85.4%
2025-12-09 13:28:11,771 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:29:00,953 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:29:00,954 DeMo.train INFO: Best mAP: 69.5%
2025-12-09 13:29:00,956 DeMo.train INFO: Best Rank-1: 70.6%
2025-12-09 13:29:00,957 DeMo.train INFO: Best Rank-5: 80.5%
2025-12-09 13:29:00,959 DeMo.train INFO: Best Rank-10: 85.4%
2025-12-09 13:29:00,960 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:29:11,326 DeMo.train INFO: Epoch[8] Iteration[10/54] Loss: 2.591, Acc: 0.744, Base Lr: 5.00e-06
2025-12-09 13:29:16,576 DeMo.train INFO: Epoch[8] Iteration[20/54] Loss: 2.557, Acc: 0.767, Base Lr: 5.00e-06
2025-12-09 13:29:19,251 DeMo.train INFO: Epoch[8] Iteration[30/54] Loss: 2.543, Acc: 0.795, Base Lr: 5.00e-06
2025-12-09 13:29:21,757 DeMo.train INFO: Epoch[8] Iteration[40/54] Loss: 2.529, Acc: 0.804, Base Lr: 5.00e-06
2025-12-09 13:29:24,250 DeMo.train INFO: Epoch[8] Iteration[50/54] Loss: 2.536, Acc: 0.810, Base Lr: 5.00e-06
2025-12-09 13:29:25,130 DeMo.train INFO: Epoch 8 done. Time per batch: 0.456[s] Speed: 140.3[samples/s]
2025-12-09 13:29:25,133 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:29:25,134 DeMo.train INFO: Current is the [moe,ori] feature testing!
2025-12-09 13:29:25,135 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The test feature is normalized
=> Computing DistMat with euclidean_distance
2025-12-09 13:29:34,367 DeMo.train INFO: Validation Results - Epoch: 8
2025-12-09 13:29:34,368 DeMo.train INFO: mAP: 66.5%
2025-12-09 13:29:34,369 DeMo.train INFO: CMC curve, Rank-1  :69.3%
2025-12-09 13:29:34,370 DeMo.train INFO: CMC curve, Rank-5  :80.1%
2025-12-09 13:29:34,370 DeMo.train INFO: CMC curve, Rank-10 :84.2%
2025-12-09 13:29:34,371 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:29:35,621 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:29:35,621 DeMo.train INFO: Best mAP: 69.5%
2025-12-09 13:29:35,622 DeMo.train INFO: Best Rank-1: 70.6%
2025-12-09 13:29:35,623 DeMo.train INFO: Best Rank-5: 80.5%
2025-12-09 13:29:35,623 DeMo.train INFO: Best Rank-10: 85.4%
2025-12-09 13:29:35,624 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:29:42,819 DeMo.train INFO: Epoch[9] Iteration[10/54] Loss: 2.534, Acc: 0.758, Base Lr: 5.00e-06
2025-12-09 13:29:45,405 DeMo.train INFO: Epoch[9] Iteration[20/54] Loss: 2.532, Acc: 0.762, Base Lr: 5.00e-06
2025-12-09 13:29:47,953 DeMo.train INFO: Epoch[9] Iteration[30/54] Loss: 2.533, Acc: 0.786, Base Lr: 5.00e-06
2025-12-09 13:29:50,510 DeMo.train INFO: Epoch[9] Iteration[40/54] Loss: 2.521, Acc: 0.809, Base Lr: 5.00e-06
2025-12-09 13:29:53,029 DeMo.train INFO: Epoch[9] Iteration[50/54] Loss: 2.516, Acc: 0.832, Base Lr: 5.00e-06
2025-12-09 13:29:53,920 DeMo.train INFO: Epoch 9 done. Time per batch: 0.345[s] Speed: 185.4[samples/s]
2025-12-09 13:29:53,921 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-12-09 13:29:53,921 DeMo.train INFO: Current is the [moe,ori] feature testing!
2025-12-09 13:29:53,921 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The test feature is normalized
=> Computing DistMat with euclidean_distance
2025-12-09 13:29:59,312 DeMo.train INFO: Validation Results - Epoch: 9
2025-12-09 13:29:59,312 DeMo.train INFO: mAP: 69.9%
2025-12-09 13:29:59,312 DeMo.train INFO: CMC curve, Rank-1  :73.1%
2025-12-09 13:29:59,312 DeMo.train INFO: CMC curve, Rank-5  :81.3%
2025-12-09 13:29:59,312 DeMo.train INFO: CMC curve, Rank-10 :85.5%
2025-12-09 13:29:59,312 DeMo.train INFO: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
