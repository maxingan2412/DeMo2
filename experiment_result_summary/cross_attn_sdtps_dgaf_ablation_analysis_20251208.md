# SDTPS 与 DGAF 跨注意力机制消融实验分析报告

**实验日期**: 2025-12-08
**实验目的**: 对比分析 SDTPS (Sparse-Dense Token Pooling Strategy) 和 DGAF V3 (Dual-Gated Adaptive Fusion) 两个模块在不同配置下的性能表现
**数据集**: MSVR310 (车辆重识别), RGBNT100 (车辆重识别)

---

## 一、实验概述

本次实验在两个多模态车辆重识别数据集上进行了 4 组消融实验，旨在验证 SDTPS 和 DGAF V3 模块的独立作用及组合效果。实验设置包括：

1. **Baseline**: 不使用 SDTPS 和 DGAF
2. **SDTPS_attn_only**: 仅使用 SDTPS（带注意力机制）
3. **DGAFv3_only**: 仅使用 DGAF V3
4. **SDTPS_attn_DGAFv3**: 同时使用 SDTPS 和 DGAF V3

所有实验均基于 ViT-B-16 骨干网络，禁用了 HDM 和 ATM 模块，采用 DIRECT=1 的直接拼接模式。

---

## 二、实验配置对比

### 2.1 基础配置

| 配置项 | 数值 |
|--------|------|
| 骨干网络 | ViT-B-16 |
| 输入尺寸 | 128 × 256 |
| 优化器 | Adam |
| 批次大小 | 64 |
| HDM | False |
| ATM | False |
| DIRECT 模式 | 1 (直接拼接) |

### 2.2 训练超参数

| 参数 | MSVR310 | RGBNT100 |
|------|---------|----------|
| 学习率 | 0.00035 | 0.00035 |
| 训练轮数 | 50 | 30 |
| Warmup | 10 轮 | 10 轮 |
| LR衰减步骤 | [30, 40] | [20, 25] |
| 衰减因子 | 0.1 | 0.1 |

### 2.3 模块配置差异

| 实验组 | USE_SDTPS | USE_DGAF | SDTPS_CROSS_ATTN_TYPE | SDTPS_CROSS_ATTN_HEADS |
|--------|-----------|----------|----------------------|----------------------|
| baseline | False | False | - | - |
| SDTPS_attn_only | True | False | attention | 4 |
| DGAFv3_only | False | True | - | - |
| SDTPS_attn_DGAFv3 | True | True | attention | 4 |

---

## 三、模型复杂度分析

### 3.1 MSVR310 数据集

| 实验组 | 参数量 (M) | GFLOPs | 相对Baseline增量 (参数) | 相对Baseline增量 (FLOPs) |
|--------|-----------|--------|----------------------|------------------------|
| baseline | 87.97 | 34.28 | - | - |
| SDTPS_attn_only | 93.31 | 34.63 | +5.34M (+6.07%) | +0.35G (+1.02%) |
| DGAFv3_only | 90.58 | 34.48 | +2.61M (+2.97%) | +0.20G (+0.58%) |
| SDTPS_attn_DGAFv3 | 95.67 | 34.70 | +7.70M (+8.75%) | +0.42G (+1.23%) |

### 3.2 RGBNT100 数据集

| 实验组 | 参数量 (M) | GFLOPs | 相对Baseline增量 (参数) | 相对Baseline增量 (FLOPs) |
|--------|-----------|--------|----------------------|------------------------|
| baseline | 87.81 | 34.28 | - | - |
| SDTPS_attn_only | 92.98 | 34.63 | +5.17M (+5.89%) | +0.35G (+1.02%) |
| DGAFv3_only | 90.25 | 34.48 | +2.44M (+2.78%) | +0.20G (+0.58%) |
| SDTPS_attn_DGAFv3 | 95.35 | 34.70 | +7.54M (+8.59%) | +0.42G (+1.23%) |

**关键发现**:
- SDTPS 模块引入约 5.3M 参数和 0.35G FLOPs
- DGAF V3 模块引入约 2.5M 参数和 0.20G FLOPs
- 两模块组合时参数增量接近线性叠加，计算量增量略超线性
- 整体计算开销增幅控制在 1.5% 以内，参数增幅约 8-9%

---

## 四、性能指标对比

### 4.1 MSVR310 数据集 (310类车辆)

| 实验组 | Best Rank-1 (%) | Best mAP (%) | Rank-1提升 | mAP提升 |
|--------|----------------|--------------|-----------|---------|
| baseline | 61.6 | 45.5 | - | - |
| SDTPS_attn_only | 61.1 | 46.0 | -0.5 | +0.5 |
| DGAFv3_only | 60.9 | 44.4 | -0.7 | -1.1 |
| SDTPS_attn_DGAFv3 | **58.2** | **42.8** | -3.4 | -2.7 |

**训练过程最佳性能出现轮次**:
- baseline: Rank-1 在第38轮达到峰值61.6%, mAP在第36轮达到峰值45.5%
- SDTPS_attn_only: 性能相对稳定，在第27轮达到最佳mAP 46.0%
- DGAFv3_only: 在第25轮达到最佳Rank-1 60.9%
- SDTPS_attn_DGAFv3: 在第44轮达到最佳Rank-1 58.2%

### 4.2 RGBNT100 数据集 (100类车辆)

| 实验组 | Best Rank-1 (%) | Best mAP (%) | Rank-1提升 | mAP提升 |
|--------|----------------|--------------|-----------|---------|
| baseline | 94.5 | 83.6 | - | - |
| SDTPS_attn_only | 91.7 | 79.7 | -2.8 | -3.9 |
| DGAFv3_only | 94.9 | 83.5 | +0.4 | -0.1 |
| SDTPS_attn_DGAFv3 | **94.1** | **82.7** | -0.4 | -0.9 |

**训练过程最佳性能出现轮次**:
- baseline: Rank-1 在第7轮达到峰值94.5%, mAP在第9轮达到峰值83.6%
- SDTPS_attn_only: 在第10轮达到最佳，显著早于其他配置
- DGAFv3_only: 在第6轮快速达到最佳Rank-1 94.9%
- SDTPS_attn_DGAFv3: 在第11轮达到最佳性能

---

## 五、深入分析与发现

### 5.1 模块独立效果分析

#### SDTPS (Sparse-Dense Token Pooling Strategy)

**在 MSVR310 上**:
- Rank-1: 61.6% → 61.1% (-0.5%)
- mAP: 45.5% → 46.0% (+0.5%)
- **结论**: 对 Rank-1 略有负面影响，但提升了 mAP，说明改善了整体检索质量

**在 RGBNT100 上**:
- Rank-1: 94.5% → 91.7% (-2.8%)
- mAP: 83.6% → 79.7% (-3.9%)
- **结论**: 在较简单数据集上性能下降明显，可能由于过度稀疏化

**综合评价**: SDTPS 在复杂数据集(MSVR310)上表现更好，在简单数据集(RGBNT100)上可能引入过度正则化。

#### DGAF V3 (Dual-Gated Adaptive Fusion)

**在 MSVR310 上**:
- Rank-1: 61.6% → 60.9% (-0.7%)
- mAP: 45.5% → 44.4% (-1.1%)
- **结论**: 性能略有下降，可能门控机制在该数据集上未充分发挥作用

**在 RGBNT100 上**:
- Rank-1: 94.5% → 94.9% (+0.4%)
- mAP: 83.6% → 83.5% (-0.1%)
- **结论**: 基本持平甚至略有提升，显示了在简单数据集上的稳定性

**综合评价**: DGAF V3 在不同数据集上表现差异较大，在 RGBNT100 上更有效。

### 5.2 模块组合效果分析

#### 在 MSVR310 上的组合效果

组合后性能显著下降（Rank-1: -3.4%, mAP: -2.7%），甚至低于单独使用任一模块。这表明：

1. **负面交互**: 两个模块之间存在负面交互效应
2. **过度复杂化**: 在 MSVR310 这样的中等规模数据集上，模块叠加可能导致过拟合
3. **优化困难**: 组合模块增加了优化难度，可能需要不同的超参数配置

#### 在 RGBNT100 上的组合效果

组合后性能下降幅度较小（Rank-1: -0.4%, mAP: -0.9%），优于单独使用 SDTPS，但不如单独使用 DGAF V3。这表明：

1. **部分互补**: 组合在一定程度上缓解了 SDTPS 的负面影响
2. **仍有冲突**: 但未能达到最优的 DGAF V3 单模块性能
3. **训练稳定性**: RGBNT100 上训练更快收敛，早期即达到较好效果

### 5.3 数据集差异分析

| 特征 | MSVR310 | RGBNT100 |
|------|---------|----------|
| 类别数 | 310 | 100 |
| 任务复杂度 | 高 | 中 |
| Baseline性能 | 61.6% / 45.5% | 94.5% / 83.6% |
| SDTPS效果 | 轻微提升mAP | 显著下降 |
| DGAF效果 | 轻微下降 | 基本持平 |
| 组合效果 | 显著负面 | 轻微负面 |

**关键洞察**:
1. **任务难度影响**: MSVR310 (310类) 比 RGBNT100 (100类) 更具挑战性，从 Baseline 性能差异可见
2. **模块适用性**: 复杂任务和简单任务对模块的响应完全不同
3. **性能天花板**: RGBNT100 上 Baseline 已达到 94.5%，改进空间有限，新模块难以带来提升

### 5.4 收敛速度分析

**MSVR310**:
- Baseline: 需要30-40轮达到最佳
- 带模块配置: 收敛时间相似或略长

**RGBNT100**:
- Baseline: 7-9轮即达到最佳
- SDTPS/DGAF: 6-11轮达到最佳
- **结论**: RGBNT100 数据集相对简单，所有配置都能快速收敛

---

## 六、计算效率分析

### 6.1 参数效率 (Parameters Efficiency)

| 数据集 | 配置 | 参数增量 | Rank-1性能变化 | 参数效率 (Δ性能/ΔM参数) |
|--------|------|---------|---------------|----------------------|
| MSVR310 | SDTPS | +5.34M | -0.5% | -0.094%/M |
| MSVR310 | DGAF | +2.61M | -0.7% | -0.268%/M |
| MSVR310 | 组合 | +7.70M | -3.4% | -0.442%/M |
| RGBNT100 | SDTPS | +5.17M | -2.8% | -0.542%/M |
| RGBNT100 | DGAF | +2.44M | +0.4% | +0.164%/M |
| RGBNT100 | 组合 | +7.54M | -0.4% | -0.053%/M |

**结论**:
- 在 MSVR310 上，所有配置的参数效率均为负
- 在 RGBNT100 上，仅 DGAF 显示正参数效率
- 组合模块的参数效率最差

### 6.2 计算效率 (FLOPs Efficiency)

所有配置的 FLOPs 增量控制在 1.5% 以内，相对于参数量的大幅增加，计算开销增幅较小，说明新增模块主要是参数密集型而非计算密集型操作。

---

## 七、结论与建议

### 7.1 主要结论

1. **模块独立性问题**: SDTPS 和 DGAF V3 作为独立模块时，未能在两个数据集上都带来性能提升

2. **负面组合效应**: 两模块组合后在两个数据集上均出现性能下降，且在 MSVR310 上下降显著

3. **数据集敏感性**:
   - MSVR310 (复杂任务): SDTPS 略有帮助，DGAF 略有损害
   - RGBNT100 (简单任务): DGAF 持平，SDTPS 显著损害

4. **计算成本**: 模块引入了 2.5-5.3M 额外参数，但 FLOPs 增幅仅 0.6-1.2%

### 7.2 技术建议

#### 对 SDTPS 的建议:

1. **调整稀疏率**: 当前 SDTPS_SPARSE_RATIO=0.7 可能过高，建议在 RGBNT100 上尝试更低的稀疏率 (0.4-0.6)
2. **自适应稀疏**: 考虑根据数据集复杂度动态调整稀疏策略
3. **注意力头数**: 当前使用 4 个注意力头，可尝试增加到 8 个以提升表达能力
4. **跨模态交互**: SDTPS_CROSS_ATTN_TYPE 可尝试其他注意力机制变体

#### 对 DGAF V3 的建议:

1. **门控初始化**: 当前 DGAF_INIT_ALPHA=0.5，可尝试更小的初始值 (0.3) 以减少早期影响
2. **温度参数**: DGAF_TAU=1.0 可能不够soft，建议尝试 2.0-5.0 的范围
3. **注意力头数**: DGAF_NUM_HEADS=8，在 MSVR310 上可尝试减少到 4 以降低复杂度

#### 对模块组合的建议:

1. **分阶段训练**: 先训练 Baseline 至收敛，再逐步引入 SDTPS 和 DGAF
2. **独立损失权重**: 为 SDTPS 和 DGAF 设置独立的损失权重，进行更精细的调优
3. **模块互斥**: 基于当前结果，建议在实际应用中仅使用单一模块而非组合
4. **超参数搜索**: 组合模块需要重新进行超参数搜索，Baseline 的超参数可能不适用

### 7.3 实验设计建议

1. **扩大实验**: 在 RGBNT201 等其他数据集上验证模块效果
2. **消融更细致**: 分别测试 SDTPS 的稀疏化和注意力组件的独立作用
3. **损失分析**: 记录训练过程中各组件损失的变化曲线，分析优化过程
4. **特征可视化**: 可视化 SDTPS 和 DGAF 的中间特征，理解其作用机制
5. **长期训练**: 当前 50 轮可能不够，建议扩展至 80-100 轮观察是否有后期提升

### 7.4 最终推荐配置

基于当前实验结果：

**对于 MSVR310 (复杂任务)**:
- 推荐使用 **Baseline** 或 **仅SDTPS** 配置
- 预期性能: Rank-1 ≈ 61%, mAP ≈ 45-46%

**对于 RGBNT100 (简单任务)**:
- 推荐使用 **Baseline** 或 **仅DGAF** 配置
- 预期性能: Rank-1 ≈ 94-95%, mAP ≈ 83-84%

**通用建议**:
- 在没有充分调优的情况下，避免使用 SDTPS+DGAF 组合
- 优先优化 Baseline 模型，再考虑引入额外模块

---

## 八、附录

### 8.1 实验日志文件路径

**MSVR310**:
- logs/MSVR310_cross_attn_20251208_061536/baseline.log
- logs/MSVR310_cross_attn_20251208_061536/SDTPS_attn_only.log
- logs/MSVR310_cross_attn_20251208_061536/DGAFv3_only.log
- logs/MSVR310_cross_attn_20251208_061536/SDTPS_attn_DGAFv3.log

**RGBNT100**:
- logs/RGBNT100_cross_attn_20251208_061536/baseline.log
- logs/RGBNT100_cross_attn_20251208_061536/SDTPS_attn_only.log
- logs/RGBNT100_cross_attn_20251208_061536/DGAFv3_only.log
- logs/RGBNT100_cross_attn_20251208_061536/SDTPS_attn_DGAFv3.log

### 8.2 关键配置参数总结

```yaml
# SDTPS 相关参数
USE_SDTPS: True/False
SDTPS_SPARSE_RATIO: 0.7
SDTPS_AGGR_RATIO: 0.5
SDTPS_BETA: 0.25
SDTPS_LOSS_WEIGHT: 2.0
SDTPS_CROSS_ATTN_TYPE: 'attention'
SDTPS_CROSS_ATTN_HEADS: 4

# DGAF 相关参数
USE_DGAF: True/False
DGAF_VERSION: 'v3'
DGAF_TAU: 1.0
DGAF_INIT_ALPHA: 0.5
DGAF_NUM_HEADS: 8
```

### 8.3 性能趋势图数据

| Epoch | MSVR310 Baseline mAP | MSVR310 SDTPS mAP | MSVR310 DGAF mAP | MSVR310 组合 mAP |
|-------|---------------------|-------------------|------------------|-----------------|
| 1 | 15.1 | 19.2 | 16.2 | 11.4 |
| 5 | 38.4 | 34.4 | 35.4 | 24.0 |
| 10 | 43.9 | 36.7 | 42.7 | 27.4 |
| 20 | 44.6 | 42.5 | 44.1 | 40.3 |
| 30 | 44.7 | 46.0 | 44.4 | 40.4 |
| 40 | 45.3 | 46.0 | 44.4 | 41.3 |
| 50 | 45.2 | 46.0 | 44.4 | 41.3 |

---

**报告生成时间**: 2025-12-08
**分析工具**: Claude Code
**数据来源**: 实验日志自动提取
