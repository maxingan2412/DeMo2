# SEPSä»»åŠ¡è¯¦è§£ï¼šä¸ºä»€ä¹ˆç”¨MSE Lossè€Œä¸ç”¨CE Lossï¼Ÿ

## ç›®å½•
1. [MSE Loss vs CE Loss å¯¹æ¯”](#mse-loss-vs-ce-loss-å¯¹æ¯”)
2. [ä¸ºä»€ä¹ˆSEPSä¸ç”¨CE Loss](#ä¸ºä»€ä¹ˆsepsä¸ç”¨ce-loss)
3. [SEPSä»»åŠ¡å®Œæ•´è¯´æ˜](#sepsä»»åŠ¡å®Œæ•´è¯´æ˜)
4. [æ•°æ®é›†è¯¦è§£](#æ•°æ®é›†è¯¦è§£)
5. [è¾“å…¥è¾“å‡ºç¤ºä¾‹](#è¾“å…¥è¾“å‡ºç¤ºä¾‹)

---

## MSE Loss vs CE Loss å¯¹æ¯”

### 1. æ•°å­¦å®šä¹‰

#### MSE Loss (Mean Squared Error)

```python
L_MSE = (1/N) Î£ (y_pred - y_true)Â²

# PyTorch
loss = nn.MSELoss()
output = loss(predictions, targets)
```

**ç‰¹ç‚¹**:
- è¾“å‡º: è¿ç»­å€¼ï¼ˆå›å½’ï¼‰
- ç›®æ ‡: è¿ç»­å€¼
- èŒƒå›´: [0, +âˆ)

#### CE Loss (Cross Entropy)

```python
L_CE = -Î£ y_true * log(y_pred)

# PyTorch (å¤šåˆ†ç±»)
loss = nn.CrossEntropyLoss()
output = loss(logits, class_labels)  # logits: (N, C), labels: (N,)

# PyTorch (äºŒåˆ†ç±»)
loss = nn.BCELoss()
output = loss(probs, targets)  # probs: (N,), targets: (N,)
```

**ç‰¹ç‚¹**:
- è¾“å‡º: æ¦‚ç‡åˆ†å¸ƒï¼ˆåˆ†ç±»ï¼‰
- ç›®æ ‡: ç±»åˆ«æ ‡ç­¾ï¼ˆç¦»æ•£ï¼‰
- èŒƒå›´: [0, +âˆ)

### 2. é€‚ç”¨åœºæ™¯å¯¹æ¯”

| ç»´åº¦ | MSE Loss | CE Loss |
|-----|----------|---------|
| **ä»»åŠ¡ç±»å‹** | å›å½’ã€æ‹Ÿåˆ | åˆ†ç±»ã€æ¦‚ç‡ä¼°è®¡ |
| **è¾“å‡ºç±»å‹** | è¿ç»­å€¼ | ç±»åˆ«/æ¦‚ç‡ |
| **ç›®æ ‡ç±»å‹** | è¿ç»­å€¼ | ç¦»æ•£æ ‡ç­¾ |
| **å…¸å‹åº”ç”¨** | é¢„æµ‹æˆ¿ä»·ã€æ¸©åº¦ã€æ¯”ä¾‹ | åˆ†ç±»å›¾åƒã€æ–‡æœ¬åˆ†ç±» |
| **æ¢¯åº¦ç‰¹æ€§** | çº¿æ€§ | æŒ‡æ•°ï¼ˆæ¥è¿‘0/1æ—¶æ¢¯åº¦å°ï¼‰ |

### 3. å…·ä½“ç¤ºä¾‹

#### MSE Lossç¤ºä¾‹

```python
# ä»»åŠ¡ï¼šé¢„æµ‹é€‰æ‹©äº†å¤šå°‘æ¯”ä¾‹çš„patch
predictions = torch.tensor([0.48, 0.52, 0.45])  # é¢„æµ‹æ¯”ä¾‹
targets = torch.tensor([0.5, 0.5, 0.5])          # ç›®æ ‡æ¯”ä¾‹

mse_loss = ((predictions - targets) ** 2).mean()
# = ((0.48-0.5)Â² + (0.52-0.5)Â² + (0.45-0.5)Â²) / 3
# = (0.0004 + 0.0004 + 0.0025) / 3
# = 0.0011
```

#### CE Lossç¤ºä¾‹

```python
# ä»»åŠ¡ï¼šåˆ†ç±»è¿™ä¸ªpatchæ˜¯å¦åº”è¯¥ä¿ç•™
logits = torch.tensor([[2.0, 0.1],    # patch 0: æ›´å¯èƒ½æ˜¯ç±»åˆ«0(ä¿ç•™)
                       [0.3, 1.5]])    # patch 1: æ›´å¯èƒ½æ˜¯ç±»åˆ«1(ä¸¢å¼ƒ)
labels = torch.tensor([0, 1])          # ground truth

ce_loss = nn.CrossEntropyLoss()(logits, labels)
# = -log(softmax([2.0, 0.1])[0]) - log(softmax([0.3, 1.5])[1])
# â‰ˆ 0.126 + 0.379 = 0.505
```

---

## ä¸ºä»€ä¹ˆSEPSä¸ç”¨CE Lossï¼Ÿ

### SEPSä¸­çš„ä¸¤ä¸ªæŸå¤±åˆ†æ

#### 1. L_align (å¯¹æ¯”æŸå¤±) - ä¸ºä»€ä¹ˆä¸ç”¨CE?

**ä»»åŠ¡æ€§è´¨**: **æ’åº/æ£€ç´¢ä»»åŠ¡**ï¼Œä¸æ˜¯åˆ†ç±»ä»»åŠ¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            åˆ†ç±» vs æ’åºçš„æœ¬è´¨åŒºåˆ«                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

åˆ†ç±»ä»»åŠ¡:
    è¾“å…¥: ä¸€ä¸ªå›¾åƒ
    è¾“å‡º: å±äºå“ªä¸ªç±»åˆ« (ç‹—/çŒ«/é¸Ÿ/...)
    ç›®æ ‡: é¢„æµ‹æ­£ç¡®çš„ç±»åˆ«æ ‡ç­¾
    æŸå¤±: CE Loss

    Example:
    - å›¾åƒ â†’ æ¨¡å‹ â†’ [0.1, 0.8, 0.1] (ç‹—/çŒ«/é¸Ÿ)
    - çœŸå®æ ‡ç­¾: "çŒ«" (index=1)
    - CE Loss: -log(0.8) = 0.223

æ’åº/æ£€ç´¢ä»»åŠ¡:
    è¾“å…¥: ä¸€ä¸ªå›¾åƒ + å¤šä¸ªæ–‡æœ¬
    è¾“å‡º: å“ªä¸ªæ–‡æœ¬ä¸å›¾åƒæœ€åŒ¹é… (ç›¸ä¼¼åº¦åˆ†æ•°)
    ç›®æ ‡: æ­£ç¡®çš„æ–‡æœ¬æ’åœ¨å‰é¢
    æŸå¤±: Ranking Loss / Triplet Loss

    Example:
    - å›¾åƒIä¸æ–‡æœ¬[T1, T2, T3]çš„ç›¸ä¼¼åº¦
    - sims = [0.9, 0.3, 0.5]
    - çœŸå®åŒ¹é…: T1
    - Triplet Loss: [Î± - 0.9 + max(0.3, 0.5)]_+
                  = [0.2 - 0.9 + 0.5]_+ = 0
```

**ä¸ºä»€ä¹ˆä¸ç”¨CE Loss?**

âŒ **CE Lossçš„é—®é¢˜**:
```python
# å¦‚æœç”¨CE Loss
sims = [0.9, 0.3, 0.5]  # ä¸3ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦
labels = 0               # ç¬¬0ä¸ªæ–‡æœ¬æ˜¯æ­£ç¡®çš„

# Softmaxå½’ä¸€åŒ–
probs = softmax(sims) = [0.56, 0.16, 0.28]

# CE Loss
ce_loss = -log(0.56) = 0.58

# é—®é¢˜1: å¿…é¡»å½’ä¸€åŒ–ä¸ºæ¦‚ç‡åˆ†å¸ƒï¼ˆå’Œ=1ï¼‰
#       ä½†ç›¸ä¼¼åº¦æœ¬èº«æ²¡æœ‰è¿™ä¸ªçº¦æŸ
# é—®é¢˜2: åªå…³å¿ƒæ­£ç¡®ç±»åˆ«çš„æ¦‚ç‡ï¼Œä¸å…³å¿ƒè´Ÿæ ·æœ¬çš„æ’åº
#       ä½†æ£€ç´¢éœ€è¦æ‰€æœ‰è´Ÿæ ·æœ¬éƒ½æ’åœ¨æ­£æ ·æœ¬åé¢
# é—®é¢˜3: ä¸èƒ½å¤„ç†ä¸€å›¾å¤šæ–‡çš„æƒ…å†µ
```

âœ… **Triplet Lossçš„ä¼˜åŠ¿**:
```python
# Triplet Loss
sims = [0.9, 0.3, 0.5]  # ä¸éœ€è¦å½’ä¸€åŒ–
positive = 0.9
hardest_negative = max(0.3, 0.5) = 0.5

triplet_loss = [margin - positive + hardest_negative]_+
             = [0.2 - 0.9 + 0.5]_+ = 0

# ä¼˜åŠ¿1: ç›´æ¥ä¼˜åŒ–ç›¸å¯¹æ’åºï¼Œä¸éœ€è¦æ¦‚ç‡å½’ä¸€åŒ–
# ä¼˜åŠ¿2: æ˜ç¡®è¦æ±‚ positive - negative >= margin
# ä¼˜åŠ¿3: å¯å¤„ç†ä¸€å›¾å¤šæ–‡ï¼ˆå¤šä¸ªæ­£æ ·æœ¬ï¼‰
```

**å¯¹æ¯”è¡¨**:

| ç»´åº¦ | CE Loss | Triplet Loss (SEPSä½¿ç”¨) |
|-----|---------|------------------------|
| **ä»»åŠ¡** | åˆ†ç±» | æ’åº/æ£€ç´¢ |
| **è¾“å‡º** | ç±»åˆ«æ¦‚ç‡ | ç›¸ä¼¼åº¦åˆ†æ•° |
| **çº¦æŸ** | Î£p_i = 1 | æ— çº¦æŸ |
| **ä¼˜åŒ–ç›®æ ‡** | æœ€å¤§åŒ–æ­£ç¡®ç±»åˆ«æ¦‚ç‡ | æ‹‰å¤§æ­£è´Ÿæ ·æœ¬é—´éš” |
| **å¤šæ­£æ ·æœ¬** | âŒ ä¸æ”¯æŒ | âœ… æ”¯æŒ |
| **æ¢¯åº¦** | æŒ‡æ•°è¡°å‡ | çº¿æ€§ |

#### 2. L_ratio (æ¯”ä¾‹æŸå¤±) - ä¸ºä»€ä¹ˆç”¨MSE?

**ä»»åŠ¡æ€§è´¨**: **å›å½’ä»»åŠ¡** - é¢„æµ‹é€‰æ‹©æ¯”ä¾‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          æ¯”ä¾‹çº¦æŸï¼šå›å½’ä»»åŠ¡ vs åˆ†ç±»ä»»åŠ¡                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

å®é™…ä»»åŠ¡:
    é¢„æµ‹: "åº”è¯¥é€‰æ‹©å¤šå°‘æ¯”ä¾‹çš„patchï¼Ÿ"
    ç›®æ ‡: 50% (target_ratio = 0.5)
    å®é™…: 48% (actual_ratio = 0.48)

è¿™æ˜¯ä¸€ä¸ªå›å½’é—®é¢˜ï¼Œä¸æ˜¯åˆ†ç±»é—®é¢˜ï¼
```

**å¦‚æœç”¨MSE Loss (æ­£ç¡®)**:
```python
target_ratio = 0.5
actual_ratio = score_mask.mean()  # 0.48

mse_loss = (actual_ratio - target_ratio) ** 2
         = (0.48 - 0.5) ** 2
         = 0.0004

# ä¼˜åŠ¿ï¼š
# 1. ç›´æ¥ä¼˜åŒ–è¿ç»­å€¼
# 2. æ¢¯åº¦å¹³æ»‘ï¼Œè®­ç»ƒç¨³å®š
# 3. è¯¯å·®è¶Šå¤§ï¼Œæƒ©ç½šè¶Šé‡ï¼ˆå¹³æ–¹ï¼‰
```

**å¦‚æœç”¨CE Loss (é”™è¯¯)**:
```python
# å¿…é¡»æŠŠè¿ç»­çš„æ¯”ä¾‹å€¼è½¬æ¢ä¸ºç¦»æ•£ç±»åˆ«
# ä¾‹å¦‚ï¼š0-10%, 10-20%, ..., 90-100% (10ä¸ªç±»åˆ«)

actual_ratio = 0.48
# å±äºå“ªä¸ªç±»åˆ«ï¼Ÿ40-50%? è¿˜æ˜¯45-55%?
# ç±»åˆ«è¾¹ç•Œå¦‚ä½•å®šä¹‰ï¼Ÿ

# é—®é¢˜ï¼š
# 1. äººä¸ºç¦»æ•£åŒ–ï¼Œä¸¢å¤±ç²¾åº¦
# 2. ç±»åˆ«å®šä¹‰ä¸»è§‚
# 3. 0.49å’Œ0.51åº”è¯¥æŸå¤±ç›¸è¿‘ï¼Œä½†ç¦»æ•£åŒ–åå¯èƒ½å·®åˆ«å¾ˆå¤§
```

**å¯¹æ¯”è¡¨**:

| æŸå¤±å‡½æ•° | é€‚ç”¨åœºæ™¯ | SEPSçš„L_ratioä½¿ç”¨ |
|---------|---------|------------------|
| **MSE Loss** | âœ… é¢„æµ‹è¿ç»­å€¼ï¼ˆæ¯”ä¾‹ã€è§’åº¦ã€åæ ‡ï¼‰ | é¢„æµ‹patché€‰æ‹©æ¯”ä¾‹ (0.48 vs 0.5) |
| **CE Loss** | âœ… é¢„æµ‹ç¦»æ•£ç±»åˆ«ï¼ˆçŒ«/ç‹—ã€æ˜¯/å¦ï¼‰ | âŒ ä¸é€‚ç”¨ï¼ˆæ¯”ä¾‹æ˜¯è¿ç»­çš„ï¼‰ |

---

## SEPSä»»åŠ¡å®Œæ•´è¯´æ˜

### ä»»åŠ¡å®šä¹‰ï¼šè·¨æ¨¡æ€æ£€ç´¢ (Cross-Modal Retrieval)

**ä»»åŠ¡**: Image-Text Matching / Cross-Modal Retrieval
**ä¸­æ–‡**: å›¾æ–‡åŒ¹é… / è·¨æ¨¡æ€æ£€ç´¢

### ä¸¤ä¸ªå­ä»»åŠ¡

#### 1. Image-to-Text Retrieval (I2T)
ç»™å®šä¸€ä¸ªå›¾åƒï¼Œä»æ–‡æœ¬åº“ä¸­æ£€ç´¢æœ€ç›¸å…³çš„æ–‡æœ¬æè¿°

```
è¾“å…¥: ä¸€å¼ å›¾åƒ
æ–‡æœ¬åº“: ["A dog running", "A cat sleeping", "A bird flying", ...]
è¾“å‡º: æ ¹æ®ç›¸ä¼¼åº¦æ’åºçš„æ–‡æœ¬åˆ—è¡¨
è¯„ä¼°: æ­£ç¡®æ–‡æœ¬æ˜¯å¦åœ¨Top-1, Top-5, Top-10ä¸­
```

#### 2. Text-to-Image Retrieval (T2I)
ç»™å®šä¸€æ®µæ–‡æœ¬ï¼Œä»å›¾åƒåº“ä¸­æ£€ç´¢æœ€ç›¸å…³çš„å›¾åƒ

```
è¾“å…¥: ä¸€æ®µæ–‡æœ¬æè¿° "A dog running on grass"
å›¾åƒåº“: [img1, img2, img3, ...]
è¾“å‡º: æ ¹æ®ç›¸ä¼¼åº¦æ’åºçš„å›¾åƒåˆ—è¡¨
è¯„ä¼°: æ­£ç¡®å›¾åƒæ˜¯å¦åœ¨Top-1, Top-5, Top-10ä¸­
```

### ä»»åŠ¡æµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              è·¨æ¨¡æ€æ£€ç´¢ä»»åŠ¡æµç¨‹                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

è®­ç»ƒé˜¶æ®µ:
â”â”â”â”â”â”â”
è¾“å…¥Batch:
- Images: (B, 3, 224, 224)     ä¾‹å¦‚32å¼ å›¾åƒ
- Captions: (B, L_s)           æ¯å¼ å›¾åƒé…1-5ä¸ªæ–‡æœ¬æè¿°
- Dense Captions: (B, L_d)     MLLMç”Ÿæˆçš„è¯¦ç»†æè¿°

    â†“ ç¼–ç å™¨

ç‰¹å¾:
- img_embs: (B, N+1, C)
- cap_embs: (B, L_s, C)
- long_cap_embs: (B, L_d, C)

    â†“ SEPSæ¨¡å‹

ç›¸ä¼¼åº¦çŸ©é˜µ:
- sims: (B, B)
- sims[i,j] = S(Image_i, Text_j)

    â†“ æŸå¤±å‡½æ•°

ç›®æ ‡:
- sims[i,i] åº”è¯¥æ˜¯ç¬¬iè¡Œå’Œç¬¬iåˆ—çš„æœ€å¤§å€¼
  (æ­£ç¡®åŒ¹é…çš„å›¾æ–‡å¯¹ç›¸ä¼¼åº¦æœ€é«˜)

    â†“ åå‘ä¼ æ’­

ä¼˜åŒ–æ¨¡å‹å‚æ•°

æ¨ç†é˜¶æ®µ:
â”â”â”â”â”â”â”
è¾“å…¥:
- æŸ¥è¯¢å›¾åƒ/æ–‡æœ¬
- å€™é€‰æ–‡æœ¬åº“/å›¾åƒåº“

    â†“ ç¼–ç  + SEPS

ç›¸ä¼¼åº¦åˆ†æ•°:
- å¯¹æ¯ä¸ªå€™é€‰è®¡ç®—ç›¸ä¼¼åº¦

    â†“ æ’åº

æ£€ç´¢ç»“æœ:
- Top-Kç›¸ä¼¼åº¦æœ€é«˜çš„ç»“æœ
```

---

## æ•°æ®é›†è¯¦è§£

### Flickr30K

**æ¥æº**: Flickrå›¾ç‰‡å¹³å°
**è®ºæ–‡**: Young et al., "From image descriptions to visual denotations" (2014)

**æ•°æ®è§„æ¨¡**:
```
æ€»å›¾åƒæ•°: 31,784å¼ 
æ€»æ–‡æœ¬æ•°: 158,915æ¡ (æ¯å¼ å›¾åƒ5æ¡æè¿°)

æ•°æ®åˆ’åˆ†:
â”œâ”€ è®­ç»ƒé›†: 29,000å¼ å›¾åƒ, 145,000æ¡æ–‡æœ¬
â”œâ”€ éªŒè¯é›†: 1,000å¼ å›¾åƒ, 5,000æ¡æ–‡æœ¬
â””â”€ æµ‹è¯•é›†: 1,014å¼ å›¾åƒ, 5,070æ¡æ–‡æœ¬
```

**å•ä¸ªæ ·æœ¬ç¤ºä¾‹**:

```json
{
  "image_id": 12345,
  "image_path": "flickr30k-images/12345.jpg",
  "captions": [
    "A dog running on the grass.",
    "A brown dog is playing outside.",
    "A pet running in a park.",
    "Dog enjoying outdoor time.",
    "An animal in a grassy field."
  ],
  "dense_caption": "A medium-sized brown dog with floppy ears is running energetically on green grass. The dog appears to be a mixed breed, with a happy expression and its tongue hanging out. The background shows a sunny park with trees and blue sky. The grass is well-maintained and bright green, suggesting it's during spring or summer."
}
```

**æ–‡æœ¬ç‰¹ç‚¹**:
- **Sparse Caption (åŸå§‹)**: 5-15ä¸ªè¯ï¼Œç®€æ´æè¿°
- **Dense Caption (MLLMç”Ÿæˆ)**: 50-200ä¸ªè¯ï¼Œè¯¦ç»†æè¿°

### MS-COCO

**æ¥æº**: Microsoft COCO (Common Objects in Context)
**è®ºæ–‡**: Lin et al., "Microsoft COCO: Common objects in context" (2014)

**æ•°æ®è§„æ¨¡**:
```
æ€»å›¾åƒæ•°: 123,287å¼ 
æ€»æ–‡æœ¬æ•°: 616,435æ¡ (æ¯å¼ å›¾åƒ5æ¡æè¿°)

æ•°æ®åˆ’åˆ†:
â”œâ”€ è®­ç»ƒé›†: 113,287å¼ å›¾åƒ, 566,435æ¡æ–‡æœ¬
â”œâ”€ éªŒè¯é›†: 5,000å¼ å›¾åƒ, 25,000æ¡æ–‡æœ¬
â””â”€ æµ‹è¯•é›†: 5,000å¼ å›¾åƒ, 25,000æ¡æ–‡æœ¬

è¯„ä¼°æ–¹å¼:
â”œâ”€ 1K test: 5-fold cross-validation (æ¯fold 1,000å›¾åƒ, 5,000æ–‡æœ¬)
â””â”€ 5K test: å…¨éƒ¨5,000å›¾åƒ, 25,000æ–‡æœ¬
```

**å•ä¸ªæ ·æœ¬ç¤ºä¾‹**:

```json
{
  "image_id": 78901,
  "image_path": "coco/train2014/COCO_train2014_000000078901.jpg",
  "captions": [
    "A woman playing tennis on a court.",
    "Female tennis player hitting a ball.",
    "A person holding a racket on a tennis court.",
    "Woman in athletic wear playing tennis.",
    "Tennis match with a female player."
  ],
  "dense_caption": "A woman in her mid-20s wearing a white tennis outfit consisting of a sleeveless top and short skirt is positioned on a blue hard court. She is in mid-swing with a white and red tennis racket, preparing to hit a yellow tennis ball. Her long brown hair is tied back in a ponytail. The court has clear white boundary lines, and there are advertising boards visible in the background. The lighting suggests it's daytime with good weather conditions."
}
```

**æ•°æ®é›†å¯¹æ¯”**:

| ç‰¹å¾ | Flickr30K | MS-COCO |
|-----|-----------|---------|
| **å›¾åƒæ¥æº** | æ—¥å¸¸ç”Ÿæ´»ç…§ç‰‡ | æ—¥å¸¸åœºæ™¯ + ç‰©ä½“æ£€æµ‹ |
| **å›¾åƒå¤æ‚åº¦** | ğŸŸ¢ ç®€å•-ä¸­ç­‰ | ğŸŸ¡ ä¸­ç­‰-å¤æ‚ |
| **åœºæ™¯å¤šæ ·æ€§** | ğŸŸ¢ å¤šæ · | ğŸŸ¢ğŸŸ¢ éå¸¸å¤šæ · |
| **ç‰©ä½“æ•°é‡** | 1-3ä¸ªä¸»è¦ç‰©ä½“ | 2-10ä¸ªç‰©ä½“ |
| **è®­ç»ƒé›†å¤§å°** | 29K | 113K |
| **æµ‹è¯•éš¾åº¦** | ğŸŸ¢ ä¸­ç­‰ | ğŸ”´ å›°éš¾ |

---

## è¾“å…¥è¾“å‡ºç¤ºä¾‹

### å®Œæ•´æ•°æ®æµç¤ºä¾‹

```python
# ========================================
# è®­ç»ƒæ—¶çš„ä¸€ä¸ªbatch
# ========================================

batch_size = 32

# 1. å›¾åƒè¾“å…¥
images = torch.randn(32, 3, 224, 224)
# 32å¼ RGBå›¾åƒï¼Œåˆ†è¾¨ç‡224Ã—224

# 2. ç¨€ç–æ–‡æœ¬è¾“å…¥ (åŸå§‹caption)
captions = torch.tensor([
    [101, 1037, 3899, 2770, 102, 0, 0, ...],  # "A dog running" + padding
    [101, 1037, 4937, 5437, 102, 0, 0, ...],  # "A cat sleeping" + padding
    ...  # 32æ¡caption
])  # (32, L_s) L_s=æœ€å¤§é•¿åº¦ï¼Œä¾‹å¦‚30

cap_lens = torch.tensor([5, 5, 7, 6, ...])  # (32,) å®é™…æœ‰æ•ˆé•¿åº¦

# 3. ç¨ å¯†æ–‡æœ¬è¾“å…¥ (MLLMç”Ÿæˆ)
long_captions = torch.tensor([
    [101, 1037, 2512, 1011, 5048, ...],  # è¯¦ç»†æè¿° (100+ tokens)
    [101, 1037, 4937, 2007, 6081, ...],  # è¯¦ç»†æè¿°
    ...  # 32æ¡dense caption
])  # (32, L_d) L_d=æœ€å¤§é•¿åº¦ï¼Œä¾‹å¦‚200

long_cap_lens = torch.tensor([156, 189, 178, ...])  # (32,)

# 4. å›¾åƒID (ç”¨äºä¸€å›¾å¤šæ–‡)
img_ids = torch.tensor([0, 0, 0, 0, 0,   # å›¾åƒ0çš„5ä¸ªcaption
                        1, 1, 1, 1, 1,   # å›¾åƒ1çš„5ä¸ªcaption
                        ...])            # (32,)

# ========================================
# æ¨¡å‹å¤„ç†
# ========================================

# ç¼–ç 
img_embs = vision_encoder(images)         # (32, 197, 512)
cap_embs = text_encoder(captions, cap_lens)  # (32, 30, 512)
long_cap_embs = text_encoder(long_captions, long_cap_lens)  # (32, 200, 512)

# SEPSå¤„ç†
sims, score_mask = model(
    img_embs, cap_embs, cap_lens,
    long_cap_embs, long_cap_lens
)

# è¾“å‡º
sims: (32, 32)  # ç›¸ä¼¼åº¦çŸ©é˜µ
# sims[i,j] = å›¾åƒiä¸æ–‡æœ¬jçš„ç›¸ä¼¼åº¦

score_mask: (32, 32, 196) æˆ– tuple
# æ¯ä¸ªå›¾æ–‡å¯¹çš„patché€‰æ‹©å†³ç­–

# ========================================
# æŸå¤±è®¡ç®—
# ========================================

total_loss, align_loss, ratio_loss = criterion(sims, score_mask, img_ids)

# total_loss: åå‘ä¼ æ’­ç”¨
# align_loss: ç›‘æ§å›¾æ–‡åŒ¹é…è´¨é‡
# ratio_loss: ç›‘æ§patché€‰æ‹©æ¯”ä¾‹
```

### çœŸå®æ•°æ®ç¤ºä¾‹

#### Flickr30Kæ ·æœ¬

```
Image: flickr30k-images/3012345.jpg
â””â”€ ä¸€ä¸ªå¥³å­©åœ¨æµ·æ»©ç©è€çš„ç…§ç‰‡

Sparse Captions (5æ¡):
1. "A young girl playing on the beach."
2. "A child building a sandcastle."
3. "Girl in a red dress at the seaside."
4. "A kid having fun on sandy beach."
5. "Young child enjoying beach time."

Dense Caption (MLLMç”Ÿæˆ):
"A young girl approximately 5-7 years old is kneeling on a sandy beach,
building a sandcastle with a small red plastic bucket and shovel. She is
wearing a bright red summer dress with white polka dots and a white sun
hat. Her hair is blonde and appears windblown. The background shows calm
blue ocean waves and a clear sky. The sand is light beige and appears
fine-grained. The girl's expression shows concentration and joy. Several
other beachgoers can be seen in the distant background."

è¯æ•°å¯¹æ¯”:
- Sparse: å¹³å‡8ä¸ªè¯/caption
- Dense: 95ä¸ªè¯

è¯­ä¹‰å¯†åº¦å¯¹æ¯”:
- Sparse: ä¸»è¦ç‰©ä½“ï¼ˆgirl, beachï¼‰
- Dense: è¯¦ç»†ç‰¹å¾ï¼ˆå¹´é¾„ã€åŠ¨ä½œã€æœè£…ã€è¡¨æƒ…ã€ç¯å¢ƒï¼‰
```

#### MS-COCOæ ·æœ¬

```
Image: COCO_val2014_000000123456.jpg
â””â”€ æ£’çƒæ¯”èµ›åœºæ™¯

Sparse Captions (5æ¡):
1. "A baseball player swinging at a pitch."
2. "A man hitting a baseball during a game."
3. "Baseball player at bat in a stadium."
4. "Batter attempting to hit the ball."
5. "A person playing baseball on a field."

Dense Caption (MLLMç”Ÿæˆ):
"A professional baseball game in progress at a large outdoor stadium.
The batter is a right-handed player wearing a white uniform with red
pinstripes and a red helmet, number 27 visible on the back. He is in
mid-swing position, having just made contact with a white baseball.
The catcher, wearing dark blue protective gear, is crouched behind home
plate. An umpire in black attire stands behind the catcher. The stadium
features green artificial turf, white bases, and advertising boards along
the outfield walls. Crowd can be seen in the stands, mostly wearing red
and white team colors. The sky is clear and blue, suggesting a day game."

è¯æ•°å¯¹æ¯”:
- Sparse: å¹³å‡7ä¸ªè¯/caption
- Dense: 132ä¸ªè¯

ç»†èŠ‚å¢å¼º:
- Sparse: åŸºæœ¬åŠ¨ä½œï¼ˆplaying baseballï¼‰
- Dense: çƒå‘˜å§¿åŠ¿ã€è£…å¤‡ç»†èŠ‚ã€åœºåœ°ç‰¹å¾ã€è§‚ä¼—ã€å¤©æ°”
```

---

## ä¸ºä»€ä¹ˆè¿™ä¸ªä»»åŠ¡è®¾è®¡é€‚åˆMSEè€Œä¸æ˜¯CEï¼Ÿ

### åŸå› 1: ä»»åŠ¡æœ¬è´¨æ˜¯æ’åºï¼Œä¸æ˜¯åˆ†ç±»

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     å›¾åƒæ£€ç´¢ â‰  å›¾åƒåˆ†ç±»                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

å›¾åƒåˆ†ç±» (ç”¨CE Loss):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
è¾“å…¥: ä¸€å¼ å›¾åƒ
è¾“å‡º: ç±»åˆ« {çŒ«, ç‹—, é¸Ÿ, ...}
ç›®æ ‡: é¢„æµ‹æ­£ç¡®ç±»åˆ«
æŸå¤±: CE Loss

å›¾åƒæ£€ç´¢ (ç”¨Triplet/Ranking Loss):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
è¾“å…¥: ä¸€å¼ å›¾åƒ + å€™é€‰æ–‡æœ¬é›†åˆ
è¾“å‡º: ç›¸ä¼¼åº¦åˆ†æ•° [0.9, 0.3, 0.5, ...]
ç›®æ ‡: æ­£ç¡®åŒ¹é…çš„ç›¸ä¼¼åº¦æœ€é«˜
æŸå¤±: Ranking Loss (Triplet Loss)

å…³é”®åŒºåˆ«:
- åˆ†ç±»: é¢„æµ‹å±äºå“ªä¸ªå›ºå®šç±»åˆ«
- æ£€ç´¢: è®¡ç®—ä¸ä»»æ„å€™é€‰çš„ç›¸ä¼¼åº¦
```

### åŸå› 2: ç›¸ä¼¼åº¦æ˜¯è¿ç»­å€¼ï¼Œä¸æ˜¯æ¦‚ç‡

```python
# ========================================
# ç›¸ä¼¼åº¦çš„æ€§è´¨
# ========================================

# ç›¸ä¼¼åº¦æ˜¯è¿ç»­çš„å®æ•°
sims = torch.tensor([
    [0.92, 0.35, 0.47, ...],  # å›¾åƒ0ä¸å„æ–‡æœ¬
    [0.28, 0.88, 0.41, ...],  # å›¾åƒ1ä¸å„æ–‡æœ¬
    ...
])

# ç‰¹ç‚¹:
# 1. ä¸éœ€è¦å½’ä¸€åŒ–ä¸ºæ¦‚ç‡ï¼ˆä¸è¦æ±‚Î£=1ï¼‰
# 2. å¯ä»¥éƒ½å¾ˆé«˜ï¼Œä¹Ÿå¯ä»¥éƒ½å¾ˆä½
# 3. å…³å¿ƒçš„æ˜¯ç›¸å¯¹æ’åºï¼Œä¸æ˜¯ç»å¯¹æ¦‚ç‡

# å¦‚æœå¼ºè¡Œç”¨CE Loss
probs = softmax(sims, dim=1)
# é—®é¢˜ï¼šç ´åäº†åŸå§‹ç›¸ä¼¼åº¦çš„ç»å¯¹å¤§å°ä¿¡æ¯
```

### åŸå› 3: æ”¯æŒä¸€å›¾å¤šæ–‡

```python
# ========================================
# ä¸€å›¾å¤šæ–‡åœºæ™¯ (COCOæ•°æ®é›†)
# ========================================

# æ¯å¼ å›¾åƒæœ‰5ä¸ªcaption
img_ids = [0, 0, 0, 0, 0,  # å›¾åƒ0çš„5ä¸ªæè¿°
           1, 1, 1, 1, 1,  # å›¾åƒ1çš„5ä¸ªæè¿°
           ...]

# Triplet Losså¯ä»¥å¤„ç†
mask = (img_ids.unsqueeze(0) == img_ids.unsqueeze(1))
# mask[0,0-4] = True  (éƒ½æ˜¯æ­£æ ·æœ¬)
# mask[0,5-31] = False (éƒ½æ˜¯è´Ÿæ ·æœ¬)

# CE Lossæ— æ³•å¤„ç†
# CEè¦æ±‚æ¯ä¸ªæ ·æœ¬åªæœ‰1ä¸ªæ­£ç¡®ç±»åˆ«
# ä½†è¿™é‡Œæœ‰5ä¸ªæ­£ç¡®ç±»åˆ«ï¼ˆ5ä¸ªcaptionï¼‰
```

### åŸå› 4: L_ratioçº¦æŸçš„æ˜¯è¿ç»­æ¯”ä¾‹

```python
# ========================================
# æ¯”ä¾‹çº¦æŸä»»åŠ¡
# ========================================

# ç›®æ ‡: é€‰æ‹©patchçš„æ¯”ä¾‹æ¥è¿‘50%
target_ratio = 0.5

# å®é™…é€‰æ‹©çš„æ¯”ä¾‹ï¼ˆè¿ç»­å€¼ï¼‰
actual_ratio = 0.483  # 48.3%

# MSE Loss (æ­£ç¡®)
mse_loss = (0.483 - 0.5) ** 2 = 0.000289
# ç›´æ¥ä¼˜åŒ–è¿ç»­å€¼ï¼Œæ¢¯åº¦å¹³æ»‘

# CE Loss (ä¸é€‚ç”¨)
# å¿…é¡»ç¦»æ•£åŒ–: {0-20%, 20-40%, 40-60%, 60-80%, 80-100%}
# 0.483å±äºç±»åˆ«2 (40-60%)
# é—®é¢˜: 0.483å’Œ0.517åº”è¯¥æŸå¤±ç›¸è¿‘ï¼Œä½†ç¦»æ•£åŒ–åéƒ½æ˜¯ç±»åˆ«2ï¼ŒCEæ— æ³•åŒºåˆ†
```

---

## ä»»åŠ¡ç›®æ ‡ä¸è¯„ä¼°

### è¯„ä¼°æŒ‡æ ‡

#### Recall@K (R@K)

**å®šä¹‰**: æ­£ç¡®ç»“æœå‡ºç°åœ¨Top-Kä¸­çš„æ¯”ä¾‹

```python
# Image-to-Text Retrieval
# ç»™å®šå›¾åƒï¼Œæ£€ç´¢æ–‡æœ¬

npts = 1000  # 1000å¼ æµ‹è¯•å›¾åƒ
sims = (1000, 5000)  # æ¯ä¸ªå›¾åƒä¸5000ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦

for i in range(npts):
    scores = sims[i]  # ç¬¬iä¸ªå›¾åƒä¸æ‰€æœ‰æ–‡æœ¬çš„ç›¸ä¼¼åº¦
    sorted_indices = argsort(scores, descending=True)

    # æ‰¾åˆ°5ä¸ªæ­£ç¡®captionçš„æ’å
    gt_indices = [i*5, i*5+1, i*5+2, i*5+3, i*5+4]
    ranks = [where(sorted_indices == gt)[0] for gt in gt_indices]
    best_rank = min(ranks)  # æœ€å¥½çš„æ’å

    if best_rank < 1:   # Top-1
        r1_count += 1
    if best_rank < 5:   # Top-5
        r5_count += 1
    if best_rank < 10:  # Top-10
        r10_count += 1

R@1 = 100 * r1_count / npts
R@5 = 100 * r5_count / npts
R@10 = 100 * r10_count / npts
```

**ç¤ºä¾‹**:
```
æµ‹è¯•é›†: 1000å¼ å›¾åƒ, 5000æ¡æ–‡æœ¬

Image-to-Text Retrieval:
- R@1 = 86.1%  â†’ 861å¼ å›¾åƒçš„æ­£ç¡®captionåœ¨Top-1
- R@5 = 93.7%  â†’ 937å¼ å›¾åƒçš„æ­£ç¡®captionåœ¨Top-5
- R@10 = 96.9% â†’ 969å¼ å›¾åƒçš„æ­£ç¡®captionåœ¨Top-10

Text-to-Image Retrieval:
- R@1 = 86.9%  â†’ 4345æ¡æ–‡æœ¬ (86.9% of 5000) çš„æ­£ç¡®å›¾åƒåœ¨Top-1
- R@5 = 98.1%
- R@10 = 99.2%
```

#### rSum (Recall Sum)

**å®šä¹‰**: 6ä¸ªR@Kçš„æ€»å’Œ

```python
rSum = R@1_i2t + R@5_i2t + R@10_i2t
     + R@1_t2i + R@5_t2i + R@10_t2i

# SEPSåœ¨Flickr30Kçš„ç»“æœ
rSum = 86.1 + 93.7 + 96.9 + 86.9 + 98.1 + 99.2
     = 560.9
```

**æ„ä¹‰**: ç»¼åˆè¯„ä¼°åŒå‘æ£€ç´¢æ€§èƒ½çš„å•ä¸€æŒ‡æ ‡

---

## å®Œæ•´ä»»åŠ¡æµç¨‹ç¤ºä¾‹

### è®­ç»ƒæµç¨‹

```python
# ========================================
# Epoch 1: Batch 1
# ========================================

# è¾“å…¥æ•°æ®
images = load_images([
    "flickr30k/12345.jpg",
    "flickr30k/12346.jpg",
    ...  # 32å¼ å›¾åƒ
])  # (32, 3, 224, 224)

sparse_captions = [
    "A dog running on grass",
    "A cat sleeping on sofa",
    ...  # æ¯å¼ å›¾åƒ1ä¸ªcaptionï¼Œå…±32æ¡
]

dense_captions = [
    "A medium-sized brown dog with...",  # è¯¦ç»†æè¿°
    "A gray tabby cat curled up on...",
    ...  # 32æ¡detailed caption
]

# Tokenize
cap_tokens = tokenizer(sparse_captions)  # (32, 30)
long_cap_tokens = tokenizer(dense_captions)  # (32, 200)

# å›¾åƒIDï¼ˆå¦‚æœä¸€å›¾å¤šæ–‡ï¼‰
img_ids = torch.arange(32)  # [0, 1, 2, ..., 31]

# ========================================
# æ¨¡å‹å‰å‘ä¼ æ’­
# ========================================

# ç‰¹å¾ç¼–ç 
img_embs = vision_encoder(images)  # (32, 197, 512)
cap_embs = text_encoder(cap_tokens, cap_lens)  # (32, 30, 512)
long_cap_embs = text_encoder(long_cap_tokens, long_lens)  # (32, 200, 512)

# SEPSå¤„ç†
sims, score_mask = model(img_embs, cap_embs, cap_lens,
                          long_cap_embs, long_cap_lens)

# ç›¸ä¼¼åº¦çŸ©é˜µ
sims = [
    [0.92, 0.31, 0.28, ...],  # å›¾åƒ0ä¸æ‰€æœ‰æ–‡æœ¬
    [0.35, 0.89, 0.33, ...],  # å›¾åƒ1ä¸æ‰€æœ‰æ–‡æœ¬
    ...
]  # (32, 32)

# ç†æƒ³æƒ…å†µ: å¯¹è§’çº¿æœ€å¤§
# sims[0,0]=0.92 > sims[0,1-31]
# sims[1,1]=0.89 > sims[1,0,2-31]

# ========================================
# æŸå¤±è®¡ç®—
# ========================================

total_loss, align_loss, ratio_loss = criterion(sims, score_mask, img_ids)

# align_lossè®¡ç®—è¿‡ç¨‹:
diagonal = [0.92, 0.89, 0.91, ...]  # æ­£æ ·æœ¬å¯¹
hardest_negative_per_image = [0.35, 0.35, ...]  # æ¯å¼ å›¾åƒçš„æœ€éš¾è´Ÿæ ·æœ¬

triplet_loss_i2t = sum([margin - 0.92 + 0.35]_+)  # Imageâ†’Text
                 = sum([0.2 - 0.92 + 0.35]_+)
                 = sum([-0.37]_+) = 0  # æ­£æ ·æœ¬å·²è¶…è¿‡margin

# ratio_lossè®¡ç®—è¿‡ç¨‹:
actual_selection = score_mask.mean() = 0.487
ratio_loss = (0.487 - 0.5) ** 2 = 0.000169

# æ€»æŸå¤±
total_loss = align_loss + 2.0 * ratio_loss

# åå‘ä¼ æ’­
total_loss.backward()
optimizer.step()
```

### æ¨ç†æµç¨‹

```python
# ========================================
# æµ‹è¯•é›†æ£€ç´¢
# ========================================

# Flickr30Kæµ‹è¯•é›†
test_images = 1014å¼ å›¾åƒ
test_captions = 5070æ¡æ–‡æœ¬ (æ¯å›¾5æ¡)

# Step 1: ç¼–ç æ‰€æœ‰æ•°æ®
img_embs_all = []
for img in test_images:
    img_emb = vision_encoder(img)
    img_embs_all.append(img_emb)
img_embs_all = torch.stack(img_embs_all)  # (1014, 197, 512)

cap_embs_all = []
for cap in test_captions:
    cap_emb = text_encoder(cap)
    cap_embs_all.append(cap_emb)
cap_embs_all = torch.stack(cap_embs_all)  # (5070, L, 512)

# Step 2: è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
sims = torch.zeros(1014, 5070)
for i in range(1014):
    for j in range(5070):
        sims[i,j] = model.forward_sim(
            img_embs_all[i:i+1],
            cap_embs_all[j:j+1],
            cap_lens[j:j+1],
            long_cap_embs_all[j:j+1],
            long_cap_lens[j:j+1]
        )

# Step 3: Image-to-Textæ£€ç´¢
for i in range(1014):
    scores = sims[i]  # ç¬¬iä¸ªå›¾åƒä¸æ‰€æœ‰5070ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦
    sorted_indices = argsort(scores, descending=True)

    # æ£€æŸ¥5ä¸ªæ­£ç¡®captionæ˜¯å¦åœ¨Top-K
    gt_captions = [i*5, i*5+1, i*5+2, i*5+3, i*5+4]

    # è®¡ç®—æœ€ä½³æ’å
    ranks = [where(sorted_indices == gt)[0] for gt in gt_captions]
    best_rank = min(ranks)

    if best_rank == 0:  # Top-1
        r1 += 1
    if best_rank < 5:   # Top-5
        r5 += 1
    if best_rank < 10:  # Top-10
        r10 += 1

R@1 = 100 * r1 / 1014  # ä¾‹å¦‚: 86.1%
R@5 = 100 * r5 / 1014  # ä¾‹å¦‚: 93.7%
R@10 = 100 * r10 / 1014  # ä¾‹å¦‚: 96.9%

# Step 4: Text-to-Imageæ£€ç´¢ï¼ˆç±»ä¼¼ï¼‰
# ...

# Step 5: è®¡ç®—rSum
rSum = R@1_i2t + R@5_i2t + R@10_i2t + R@1_t2i + R@5_t2i + R@10_t2i
```

---

## æ•°æ®é›†ç›®å½•ç»“æ„

### Flickr30K

```
data/f30k/
â”œâ”€â”€ train_caps.txt           # è®­ç»ƒé›†caption (145,000è¡Œ)
â”œâ”€â”€ train_ids.txt            # è®­ç»ƒé›†å›¾åƒID (145,000è¡Œ)
â”œâ”€â”€ test_caps.txt            # æµ‹è¯•é›†caption (5,070è¡Œ)
â”œâ”€â”€ test_ids.txt             # æµ‹è¯•é›†å›¾åƒID (5,070è¡Œ)
â”œâ”€â”€ id_mapping.json          # å›¾åƒIDåˆ°æ–‡ä»¶è·¯å¾„æ˜ å°„
â”œâ”€â”€ f30k_train.jsonl         # MLLMç”Ÿæˆçš„dense caption (è®­ç»ƒé›†)
â””â”€â”€ f30k_test.jsonl          # MLLMç”Ÿæˆçš„dense caption (æµ‹è¯•é›†)

flickr30k-images/            # å›¾åƒæ–‡ä»¶å¤¹
â”œâ”€â”€ 1000092795.jpg
â”œâ”€â”€ 10002456.jpg
â””â”€â”€ ...
```

**æ–‡ä»¶æ ¼å¼ç¤ºä¾‹**:

```
train_caps.txt:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
A dog running on the grass.
A brown dog is playing outside.
A pet running in a park.
...

train_ids.txt:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1000092795
1000092795
1000092795
1000092795
1000092795
10002456
...

f30k_train.jsonl:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
{"image_id": 1000092795, "text": "A medium-sized brown dog with..."}
{"image_id": 10002456, "text": "A young girl approximately..."}
...
```

### MS-COCO

```
data/coco/
â”œâ”€â”€ train_caps.txt           # è®­ç»ƒé›†caption (566,435è¡Œ)
â”œâ”€â”€ train_ids.txt            # è®­ç»ƒé›†å›¾åƒID (566,435è¡Œ)
â”œâ”€â”€ testall_caps.txt         # æµ‹è¯•é›†caption (25,000è¡Œ)
â”œâ”€â”€ testall_ids.txt          # æµ‹è¯•é›†å›¾åƒID (25,000è¡Œ)
â”œâ”€â”€ id_mapping.json
â”œâ”€â”€ coco_train.jsonl         # Dense captions
â””â”€â”€ coco_testall.jsonl

coco/                        # COCOå›¾åƒ
â”œâ”€â”€ train2014/
â”‚   â”œâ”€â”€ COCO_train2014_000000000009.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ val2014/
    â”œâ”€â”€ COCO_val2014_000000000042.jpg
    â””â”€â”€ ...
```

---

## ä¸ºä»€ä¹ˆä¸èƒ½ç”¨CE Lossï¼ŸæŠ€æœ¯ç»†èŠ‚

### åœºæ™¯1: ç”¨CE LossåšL_align

**å‡è®¾**: æŠŠå›¾æ–‡åŒ¹é…å½“ä½œåˆ†ç±»ä»»åŠ¡

```python
# âŒ é”™è¯¯çš„CE Lossä½¿ç”¨
# æŠŠ"æ‰¾åˆ°æ­£ç¡®æ–‡æœ¬"å½“ä½œ"åˆ†ç±»é—®é¢˜"

# è¾“å…¥
img_emb = vision_encoder(image)  # (1, 512)
candidate_texts = 5000  # å€™é€‰æ–‡æœ¬æ•°é‡

# å¦‚æœç”¨åˆ†ç±»å¤´
logits = nn.Linear(512, 5000)(img_emb)  # (1, 5000)
# æ¯ä¸ªå€™é€‰æ–‡æœ¬æ˜¯ä¸€ä¸ªç±»åˆ«

# CE Loss
label = 237  # å‡è®¾ç¬¬237ä¸ªæ–‡æœ¬æ˜¯æ­£ç¡®çš„
ce_loss = nn.CrossEntropyLoss()(logits, label)

# é—®é¢˜:
# 1. éœ€è¦ä¸ºæ¯ä¸ªæ•°æ®é›†è®­ç»ƒä¸“é—¨çš„åˆ†ç±»å¤´ï¼ˆ5000ä¸ªç±»åˆ«ï¼‰
# 2. æ–°å¢æ–‡æœ¬å°±è¦é‡æ–°è®­ç»ƒ
# 3. æ— æ³•æ³›åŒ–åˆ°æœªè§è¿‡çš„æ–‡æœ¬
# 4. ä¸€å›¾å¤šæ–‡æ—¶ï¼Œlabelåªèƒ½æ˜¯ä¸€ä¸ªæ•°å­—ï¼Œæ— æ³•è¡¨ç¤ºå¤šä¸ªæ­£ç¡®ç­”æ¡ˆ
```

**æ­£ç¡®çš„Triplet Loss**:

```python
# âœ… æ­£ç¡®çš„Ranking Lossä½¿ç”¨
# è®¡ç®—å›¾åƒä¸æ¯ä¸ªå€™é€‰æ–‡æœ¬çš„ç›¸ä¼¼åº¦

img_emb = vision_encoder(image)  # (1, 512)
text_embs = text_encoder(candidate_texts)  # (5000, 512)

# è®¡ç®—ç›¸ä¼¼åº¦ï¼ˆä¸éœ€è¦åˆ†ç±»å¤´ï¼‰
sims = img_emb @ text_embs.T  # (1, 5000)

# Triplet Loss
positive_sim = sims[0, 237]  # æ­£ç¡®æ–‡æœ¬çš„ç›¸ä¼¼åº¦
negative_sims = sims[0, [0-236, 238-4999]]  # å…¶ä»–æ–‡æœ¬
hardest_negative = negative_sims.max()

triplet_loss = [margin - positive_sim + hardest_negative]_+

# ä¼˜åŠ¿:
# 1. æ— éœ€ä¸ºæ¯ä¸ªæ•°æ®é›†è®­ç»ƒåˆ†ç±»å¤´
# 2. å¯æ³›åŒ–åˆ°ä»»æ„æ–°æ–‡æœ¬
# 3. æ”¯æŒä¸€å›¾å¤šæ–‡
# 4. ç›´æ¥ä¼˜åŒ–æ’åº
```

### åœºæ™¯2: ç”¨CE LossåšL_ratio

**å‡è®¾**: æŠŠæ¯”ä¾‹é¢„æµ‹å½“ä½œåˆ†ç±»ä»»åŠ¡

```python
# âŒ é”™è¯¯çš„CE Lossä½¿ç”¨
# æŠŠ"é¢„æµ‹é€‰æ‹©æ¯”ä¾‹"å½“ä½œ"åˆ†ç±»é—®é¢˜"

# ç¦»æ•£åŒ–æ¯”ä¾‹ä¸º10ä¸ªç±»åˆ«
# 0-10%, 10-20%, ..., 90-100%

# å®é™…é€‰æ‹©æ¯”ä¾‹
actual_ratio = 0.483  # 48.3%

# è½¬æ¢ä¸ºç±»åˆ«
class_label = int(actual_ratio * 10)  # = 4 (40-50%)

# CE Loss
logits = [...]  # 10ä¸ªç±»åˆ«çš„logits
ce_loss = nn.CrossEntropyLoss()(logits, class_label)

# é—®é¢˜:
# 1. 48.3%å’Œ49.7%åº”è¯¥æŸå¤±ç›¸è¿‘ï¼Œä½†éƒ½å±äºç±»åˆ«4ï¼ŒCEæ— æ³•åŒºåˆ†
# 2. 49.9%å’Œ50.1%å¾ˆæ¥è¿‘ï¼Œä½†åˆ†å±ç±»åˆ«4å’Œ5ï¼ŒCEè®¤ä¸ºå®ƒä»¬å·®è·å¤§
# 3. ç¦»æ•£åŒ–ä¸¢å¤±ç²¾åº¦
# 4. ç±»åˆ«è¾¹ç•Œäººä¸ºå®šä¹‰ï¼Œä¸åˆç†
```

**æ­£ç¡®çš„MSE Loss**:

```python
# âœ… æ­£ç¡®çš„MSE Lossä½¿ç”¨
# ç›´æ¥é¢„æµ‹è¿ç»­çš„æ¯”ä¾‹å€¼

actual_ratio = score_mask.mean()  # 0.483
target_ratio = 0.5

mse_loss = (actual_ratio - target_ratio) ** 2
         = (0.483 - 0.5) ** 2
         = 0.000289

# ä¼˜åŠ¿:
# 1. ç›´æ¥ä¼˜åŒ–è¿ç»­å€¼
# 2. 48.3%å’Œ49.7%çš„æŸå¤±å·®å¼‚æ­£ç¡®åæ˜ å®é™…å·®å¼‚
# 3. æ— éœ€ç¦»æ•£åŒ–
# 4. æ¢¯åº¦å¹³æ»‘
```

---

## æŸå¤±å‡½æ•°é€‰æ‹©å†³ç­–æ ‘

```
ä»»åŠ¡æ˜¯ä»€ä¹ˆ?
    â”‚
    â”œâ”€ é¢„æµ‹ç±»åˆ« (ç¦»æ•£) â†’ ç”¨ CE Loss
    â”‚   ä¾‹å¦‚: å›¾åƒåˆ†ç±»ã€æ–‡æœ¬åˆ†ç±»
    â”‚
    â”œâ”€ é¢„æµ‹è¿ç»­å€¼ (å›å½’) â†’ ç”¨ MSE Loss æˆ– MAE Loss
    â”‚   ä¾‹å¦‚: é¢„æµ‹æˆ¿ä»·ã€é¢„æµ‹æ¯”ä¾‹ã€é¢„æµ‹è§’åº¦
    â”‚
    â””â”€ æ’åº/æ£€ç´¢ â†’ ç”¨ Ranking Loss (Triplet/Contrastive)
        ä¾‹å¦‚: å›¾åƒæ£€ç´¢ã€æ¨èç³»ç»Ÿã€ç›¸ä¼¼åº¦å­¦ä¹ 

SEPSä»»åŠ¡:
    â”‚
    â”œâ”€ L_align: å›¾æ–‡æ£€ç´¢ â†’ Triplet Loss âœ…
    â”‚
    â””â”€ L_ratio: é¢„æµ‹æ¯”ä¾‹ â†’ MSE Loss âœ…
```

---

## ä»»åŠ¡å¯¹æ¯”è¡¨

### å›¾åƒæ£€ç´¢ vs å›¾åƒåˆ†ç±»

| ç»´åº¦ | å›¾åƒæ£€ç´¢ (SEPS) | å›¾åƒåˆ†ç±» (ResNet) |
|-----|----------------|------------------|
| **ä»»åŠ¡** | æ‰¾åˆ°ä¸queryæœ€ç›¸ä¼¼çš„å›¾åƒ | é¢„æµ‹å›¾åƒå±äºå“ªä¸ªç±»åˆ« |
| **è¾“å‡º** | ç›¸ä¼¼åº¦åˆ†æ•° (è¿ç»­) | ç±»åˆ«æ¦‚ç‡ (ç¦»æ•£) |
| **å€™é€‰é›†åˆ** | åŠ¨æ€ï¼ˆä»»æ„å›¾åƒ/æ–‡æœ¬ï¼‰ | å›ºå®šï¼ˆé¢„å®šä¹‰ç±»åˆ«ï¼‰ |
| **æŸå¤±å‡½æ•°** | Triplet Loss | CE Loss |
| **è¯„ä¼°æŒ‡æ ‡** | R@1, R@5, R@10, rSum | Accuracy, Top-5 Accuracy |
| **æ³›åŒ–æ€§** | âœ… å¯æ³›åŒ–åˆ°æ–°å›¾æ–‡ | âŒ åªèƒ½åˆ†ç±»å·²çŸ¥ç±»åˆ« |

### ç¤ºä¾‹å¯¹æ¯”

**å›¾åƒåˆ†ç±»**:
```
è¾“å…¥: ä¸€å¼ çŒ«çš„å›¾ç‰‡
è¾“å‡º: [0.05, 0.90, 0.05]  (ç‹—/çŒ«/é¸Ÿ)
      â””â”€ Softmaxå½’ä¸€åŒ–ï¼Œå’Œ=1
ç›®æ ‡: ç±»åˆ«æ ‡ç­¾ = 1 (çŒ«)
æŸå¤±: CE Loss = -log(0.90) = 0.105
```

**å›¾åƒæ£€ç´¢**:
```
è¾“å…¥: ä¸€å¼ çŒ«çš„å›¾ç‰‡ + å€™é€‰æ–‡æœ¬åº“
     ["A dog running", "A cat sleeping", "A bird flying"]
è¾“å‡º: [0.3, 0.9, 0.2]  (ç›¸ä¼¼åº¦ï¼Œä¸éœ€è¦å’Œ=1)
ç›®æ ‡: "A cat sleeping" æ’ç¬¬ä¸€
æŸå¤±: Triplet Loss = [0.2 - 0.9 + 0.3]_+ = 0
```

---

## æ€»ç»“

### âœ… SEPSä½¿ç”¨çš„æŸå¤±å‡½æ•°ï¼ˆå®Œæ•´ä¸”æ­£ç¡®ï¼‰

```python
SEPSLoss = ContrastiveLoss (Triplet Loss) + RatioLoss (MSE Loss)
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                     â”‚                              â”‚
              L_align (å…¬å¼6)                  L_ratio (å…¬å¼7)
              å›¾æ–‡åŒ¹é…æ’åºä»»åŠ¡                   æ¯”ä¾‹é¢„æµ‹å›å½’ä»»åŠ¡
              ä¸èƒ½ç”¨CE Loss!                    ä¸èƒ½ç”¨CE Loss!
```

### ğŸ¯ ä¸ºä»€ä¹ˆä¸ç”¨CE Lossï¼Ÿ

**L_align (Triplet Loss)**:
1. âœ… ä»»åŠ¡æ˜¯**æ’åº**ï¼Œä¸æ˜¯åˆ†ç±»
2. âœ… è¾“å‡ºæ˜¯**ç›¸ä¼¼åº¦**ï¼Œä¸æ˜¯æ¦‚ç‡
3. âœ… æ”¯æŒ**ä¸€å›¾å¤šæ–‡**ï¼ŒCEä¸æ”¯æŒ
4. âœ… å¯**æ³›åŒ–åˆ°æ–°æ–‡æœ¬**ï¼ŒCEåªèƒ½åˆ†ç±»å›ºå®šç±»åˆ«

**L_ratio (MSE Loss)**:
1. âœ… ä»»åŠ¡æ˜¯é¢„æµ‹**è¿ç»­æ¯”ä¾‹**ï¼Œä¸æ˜¯ç¦»æ•£ç±»åˆ«
2. âœ… 0.48å’Œ0.52åº”è¯¥æŸå¤±æ¥è¿‘ï¼ŒCEçš„ç¦»æ•£åŒ–åšä¸åˆ°
3. âœ… æ¢¯åº¦å¹³æ»‘ï¼Œè®­ç»ƒç¨³å®š

### ğŸ“Š SEPSä»»åŠ¡æ ¸å¿ƒ

**ä»»åŠ¡**: è·¨æ¨¡æ€æ£€ç´¢ (Cross-Modal Retrieval)
- Image-to-Text: ç»™å›¾æ‰¾æ–‡æœ¬
- Text-to-Image: ç»™æ–‡æœ¬æ‰¾å›¾

**æ•°æ®é›†**:
- Flickr30K: 31Kå›¾åƒ, 155Kæ–‡æœ¬
- MS-COCO: 123Kå›¾åƒ, 615Kæ–‡æœ¬
- æ¯å›¾5ä¸ªcaption

**è¾“å…¥**:
- Image: (B, 3, H, W)
- Sparse Text: (B, L_s) - åŸå§‹caption
- Dense Text: (B, L_d) - MLLMç”Ÿæˆ

**è¾“å‡º**:
- Similarity Matrix: (B_v, B_t)
- ç”¨äºæ’åºå’Œæ£€ç´¢

**è¯„ä¼°**:
- R@1, R@5, R@10 (Recall)
- rSum (ç»¼åˆæŒ‡æ ‡)

**æŸå¤±**:
- âœ… Triplet Loss (æ’åºä»»åŠ¡)
- âœ… MSE Loss (æ¯”ä¾‹å›å½’)
- âŒ ä¸ç”¨CE Loss (ä»»åŠ¡ä¸åŒ¹é…)

---

**ç»“è®º**: SEPSçš„æŸå¤±å‡½æ•°è®¾è®¡å®Œå…¨æ­£ç¡®ï¼Œä¸éœ€è¦ä¹Ÿä¸åº”è¯¥ä½¿ç”¨CE Lossï¼
